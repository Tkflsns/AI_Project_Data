{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e190bc7c-e3b2-4b2e-829a-3ba268722d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using converter: <class 'lincenseplateocr.utils.AttnLabelConverter'>\n",
      "Initializing TPS Transformation\n",
      "TPS 초기화: F=20, I_size=(32, 100), I_r_size=(32, 100), I_channel_num=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\KD7-3\\DataProject\\lincenseplateocr\\modules\\transformation.py:107: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.register_buffer(\"inv_delta_C\", torch.tensor(self._build_inv_delta_C(self.F, self.C)).float())  # F+3 x F+3\n",
      "D:\\KD7-3\\DataProject\\lincenseplateocr\\modules\\transformation.py:108: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.register_buffer(\"P_hat\", torch.tensor(self._build_P_hat(self.F, self.C, self.P)).float())  # n x F+3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TPS Transformation initialized\n",
      "Initializing Feature Extraction: ResNet\n",
      "Feature Extraction initialized with output size: 512\n",
      "Initializing Sequence Modeling with BiLSTM\n",
      "Sequence Modeling initialized\n",
      "Initializing Prediction: Attn\n",
      "Prediction initialized\n",
      "Fine-tuning mode: Loading pretrained model for fine-tuning\n",
      "Prediction.attention_cell.i2h.weight - requires_grad: True\n",
      "Prediction.attention_cell.h2h.weight - requires_grad: True\n",
      "Prediction.attention_cell.h2h.bias - requires_grad: True\n",
      "Prediction.attention_cell.score.weight - requires_grad: True\n",
      "Prediction.attention_cell.rnn.weight_ih - requires_grad: True\n",
      "Prediction.attention_cell.rnn.weight_hh - requires_grad: True\n",
      "Prediction.attention_cell.rnn.bias_ih - requires_grad: True\n",
      "Prediction.attention_cell.rnn.bias_hh - requires_grad: True\n",
      "Prediction.generator.weight - requires_grad: True\n",
      "Prediction.generator.bias - requires_grad: True\n",
      "\n",
      "0: 320x640 1 number_plate, 19.3ms\n",
      "Speed: 0.0ms preprocess, 19.3ms inference, 5.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Encoded label: tensor([[ 0, 35, 44,  5,  9, 78,  8,  7,  5,  2,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]], device='cuda:0')\n",
      "Prediction: ['구구구구.구구....구구구구구구구구구구구구구구구'], Ground Truth: 경기37바6530\n",
      "\n",
      "0: 320x640 1 number_plate, 0.0ms\n",
      "Speed: 0.0ms preprocess, 0.0ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Encoded label: tensor([[ 0, 35, 44,  5,  9, 78,  8,  7,  5,  2,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]], device='cuda:0')\n",
      "Prediction: ['구구구03구구.0...구구구구구구구구구구구구구구'], Ground Truth: 경기37바6530\n",
      "\n",
      "0: 288x640 1 number_plate, 15.9ms\n",
      "Speed: 0.0ms preprocess, 15.9ms inference, 0.0ms postprocess per image at shape (1, 3, 288, 640)\n",
      "Encoded label: tensor([[ 0, 35, 44,  5,  9, 78,  8,  8,  5,  9,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]], device='cuda:0')\n",
      "Prediction: ['구3333333333333333333333333'], Ground Truth: 경기37바6637\n",
      "\n",
      "0: 288x640 1 number_plate, 16.2ms\n",
      "Speed: 0.0ms preprocess, 16.2ms inference, 0.0ms postprocess per image at shape (1, 3, 288, 640)\n",
      "Encoded label: tensor([[ 0, 35, 44,  5,  9, 78,  8,  8, 10,  3,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]], device='cuda:0')\n",
      "Prediction: ['33333333333333333333333333'], Ground Truth: 경기37바6681\n",
      "\n",
      "0: 416x640 1 number_plate, 3.4ms\n",
      "Speed: 14.3ms preprocess, 3.4ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "Encoded label: tensor([[ 0, 35, 44,  5, 10, 57,  7,  6, 10,  6,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]], device='cuda:0')\n",
      "Prediction: ['33333333333333333333333333'], Ground Truth: 경기38더5484\n",
      "\n",
      "0: 416x640 1 number_plate, 0.0ms\n",
      "Speed: 0.0ms preprocess, 0.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "Encoded label: tensor([[ 0, 35, 44,  5, 10, 71,  6, 10,  8,  8,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]], device='cuda:0')\n",
      "Prediction: ['33333333333333333333333333'], Ground Truth: 경기38머4866\n",
      "\n",
      "0: 288x640 1 number_plate, 16.4ms\n",
      "Speed: 0.0ms preprocess, 16.4ms inference, 0.0ms postprocess per image at shape (1, 3, 288, 640)\n",
      "Encoded label: tensor([[ 0, 35, 44,  7,  3, 78,  4,  2,  5,  4,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]], device='cuda:0')\n",
      "Prediction: ['33333333333333333333333333'], Ground Truth: 경기51바2032\n",
      "\n",
      "0: 416x640 1 number_plate, 0.0ms\n",
      "Speed: 0.0ms preprocess, 0.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "Encoded label: tensor([[ 0, 35, 44,  9,  3, 97,  3,  6,  7,  8,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]], device='cuda:0')\n",
      "Prediction: ['33333333333333333333333333'], Ground Truth: 경기71아1456\n",
      "\n",
      "0: 416x640 1 number_plate, 15.5ms\n",
      "Speed: 0.0ms preprocess, 15.5ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "Encoded label: tensor([[ 0, 35, 44,  9,  3, 97,  3,  8,  4,  6,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]], device='cuda:0')\n",
      "Prediction: ['33333333333333333333333333'], Ground Truth: 경기71아1624\n",
      "\n",
      "0: 384x640 1 number_plate, 16.9ms\n",
      "Speed: 15.7ms preprocess, 16.9ms inference, 15.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Encoded label: tensor([[ 0, 35, 44,  9,  3, 97,  5,  3,  4,  9,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]], device='cuda:0')\n",
      "Prediction: ['33333333333333333333333333'], Ground Truth: 경기71아3127\n",
      "\n",
      "0: 448x640 1 number_plate, 0.0ms\n",
      "Speed: 0.0ms preprocess, 0.0ms inference, 13.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Encoded label: tensor([[ 0, 35, 44,  9,  3, 97,  5,  3,  7,  6,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]], device='cuda:0')\n",
      "Prediction: ['33333333336666666666666666'], Ground Truth: 경기71아3154\n",
      "\n",
      "0: 448x640 1 number_plate, 0.0ms\n",
      "Speed: 0.0ms preprocess, 0.0ms inference, 0.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Encoded label: tensor([[ 0, 35, 44,  9,  3, 97,  5,  7,  5,  6,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]], device='cuda:0')\n",
      "Prediction: ['33333333666666666666666666'], Ground Truth: 경기71아3534\n",
      "\n",
      "0: 448x640 1 number_plate, 0.0ms\n",
      "Speed: 15.1ms preprocess, 0.0ms inference, 0.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Encoded label: tensor([[ 0, 35, 44,  9,  3, 97,  5,  7, 10,  6,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]], device='cuda:0')\n",
      "Prediction: ['33333336666666666666666666'], Ground Truth: 경기71아3584\n",
      "\n",
      "0: 512x640 1 number_plate, 15.8ms\n",
      "Speed: 0.0ms preprocess, 15.8ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Encoded label: tensor([[ 0, 35, 44,  9,  3, 97,  5,  7, 10,  6,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]], device='cuda:0')\n",
      "Prediction: ['3333333366[s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s]'], Ground Truth: 경기71아3584\n",
      "\n",
      "0: 544x640 1 number_plate, 0.0ms\n",
      "Speed: 0.0ms preprocess, 0.0ms inference, 15.8ms postprocess per image at shape (1, 3, 544, 640)\n",
      "Encoded label: tensor([[ 0, 35, 44,  9,  3, 97,  5,  8, 10,  7,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]], device='cuda:0')\n",
      "Prediction: ['3333333[s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s]'], Ground Truth: 경기71아3685\n",
      "\n",
      "0: 416x640 1 number_plate, 0.0ms\n",
      "Speed: 0.0ms preprocess, 0.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "Encoded label: tensor([[ 0, 35, 44,  9,  3, 97,  8,  4,  3,  5,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]], device='cuda:0')\n",
      "Prediction: ['333333[s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s]'], Ground Truth: 경기71아6213\n",
      "\n",
      "0: 384x640 1 number_plate, 0.0ms\n",
      "Speed: 15.7ms preprocess, 0.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Encoded label: tensor([[ 0, 35, 44,  9,  3, 97,  8,  9,  2,  4,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]], device='cuda:0')\n",
      "Prediction: ['33333[s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s]'], Ground Truth: 경기71아6702\n",
      "\n",
      "0: 448x640 1 number_plate, 15.6ms\n",
      "Speed: 0.0ms preprocess, 15.6ms inference, 0.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Encoded label: tensor([[ 0, 35, 44,  9,  3, 97, 10,  2,  2,  7,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]], device='cuda:0')\n",
      "Prediction: ['3333[s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s]'], Ground Truth: 경기71아8005\n",
      "\n",
      "0: 448x640 1 number_plate, 16.1ms\n",
      "Speed: 0.0ms preprocess, 16.1ms inference, 0.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Encoded label: tensor([[ 0, 35, 44,  9,  3, 97, 10,  2,  2,  7,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]], device='cuda:0')\n",
      "Prediction: ['333[s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s]'], Ground Truth: 경기71아8005\n",
      "\n",
      "0: 416x640 1 number_plate, 14.5ms\n",
      "Speed: 0.0ms preprocess, 14.5ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "Encoded label: tensor([[ 0, 35, 44,  9,  3, 97, 10,  2,  6,  5,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]], device='cuda:0')\n",
      "Prediction: ['333[s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s]'], Ground Truth: 경기71아8043\n",
      "\n",
      "0: 384x640 1 number_plate, 0.0ms\n",
      "Speed: 15.4ms preprocess, 0.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Encoded label: tensor([[ 0, 35, 44,  9,  3, 97, 10,  2,  6,  5,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]], device='cuda:0')\n",
      "Prediction: ['333[s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s]'], Ground Truth: 경기71아8043\n",
      "\n",
      "0: 448x640 1 number_plate, 14.1ms\n",
      "Speed: 0.0ms preprocess, 14.1ms inference, 0.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Encoded label: tensor([[ 0, 35, 44,  9,  3, 97, 10,  2,  7,  4,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]], device='cuda:0')\n",
      "Prediction: ['33[s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s]'], Ground Truth: 경기71아8052\n",
      "\n",
      "0: 544x640 1 number_plate, 15.8ms\n",
      "Speed: 0.0ms preprocess, 15.8ms inference, 0.0ms postprocess per image at shape (1, 3, 544, 640)\n",
      "Encoded label: tensor([[ 0, 35, 44,  9,  3, 97, 10,  2,  7,  9,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]], device='cuda:0')\n",
      "Prediction: ['33[s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s]'], Ground Truth: 경기71아8057\n",
      "\n",
      "0: 384x640 1 number_plate, 31.3ms\n",
      "Speed: 0.0ms preprocess, 31.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Encoded label: tensor([[ 0, 35, 44,  9,  3, 97, 10,  3,  8,  4,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]], device='cuda:0')\n",
      "Prediction: ['33[s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s]'], Ground Truth: 경기71아8162\n",
      "\n",
      "0: 448x640 1 number_plate, 16.1ms\n",
      "Speed: 0.0ms preprocess, 16.1ms inference, 0.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Encoded label: tensor([[ 0, 35, 44,  9,  3, 97, 10,  7,  9,  4,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]], device='cuda:0')\n",
      "Prediction: ['33[s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s]'], Ground Truth: 경기71아8572\n",
      "\n",
      "0: 448x640 1 number_plate, 15.7ms\n",
      "Speed: 0.0ms preprocess, 15.7ms inference, 0.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Encoded label: tensor([[  0,  35,  44,   9,   3, 117,  10,   6,   8,  11,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]], device='cuda:0')\n",
      "Prediction: ['377[s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s]'], Ground Truth: 경기71자8469\n",
      "\n",
      "0: 448x640 1 number_plate, 14.3ms\n",
      "Speed: 0.0ms preprocess, 14.3ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Encoded label: tensor([[ 0, 35, 44,  9,  5, 73,  9,  9,  5, 11,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]], device='cuda:0')\n",
      "Prediction: ['37111[s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s]'], Ground Truth: 경기73모7739\n",
      "\n",
      "0: 384x640 1 number_plate, 15.2ms\n",
      "Speed: 0.0ms preprocess, 15.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Encoded label: tensor([[ 0, 35, 44,  9,  5, 78,  3,  7, 11,  9,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]], device='cuda:0')\n",
      "Prediction: ['77111188888888888888888888'], Ground Truth: 경기73바1597\n",
      "\n",
      "0: 384x640 1 number_plate, 0.0ms\n",
      "Speed: 15.7ms preprocess, 0.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Encoded label: tensor([[ 0, 35, 44,  9,  5, 97,  5,  3,  2, 11,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]], device='cuda:0')\n",
      "Prediction: ['77711888888888888888888888'], Ground Truth: 경기73아3109\n",
      "\n",
      "0: 384x640 1 number_plate, 0.0ms\n",
      "Speed: 15.6ms preprocess, 0.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Encoded label: tensor([[ 0, 35, 44,  9,  5, 97,  5,  6,  3,  5,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]], device='cuda:0')\n",
      "Prediction: ['77711188888888888888888888'], Ground Truth: 경기73아3413\n",
      "\n",
      "0: 448x640 1 number_plate, 0.0ms\n",
      "Speed: 15.6ms preprocess, 0.0ms inference, 0.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Encoded label: tensor([[ 0, 35, 44,  9,  5, 97,  5,  8,  8,  8,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]], device='cuda:0')\n",
      "Prediction: ['77711111118888888888888888'], Ground Truth: 경기73아3666\n",
      "\n",
      "0: 416x640 1 number_plate, 16.3ms\n",
      "Speed: 0.0ms preprocess, 16.3ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "Encoded label: tensor([[ 0, 35, 44,  9,  7, 78,  3,  2,  8,  7,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]], device='cuda:0')\n",
      "Prediction: ['77771117777777777777777777'], Ground Truth: 경기75바1065\n",
      "\n",
      "0: 416x640 1 number_plate, 15.1ms\n",
      "Speed: 0.0ms preprocess, 15.1ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "Encoded label: tensor([[ 0, 35, 44,  9,  7, 78,  3,  2, 11,  6,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]], device='cuda:0')\n",
      "Prediction: ['77777177777777777777777777'], Ground Truth: 경기75바1094\n",
      "\n",
      "0: 448x640 1 number_plate, 30.4ms\n",
      "Speed: 0.0ms preprocess, 30.4ms inference, 0.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Encoded label: tensor([[ 0, 35, 44,  9,  9, 78,  8,  8,  2,  5,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]], device='cuda:0')\n",
      "Prediction: ['77771177777777777777777777'], Ground Truth: 경기77바6603\n",
      "\n",
      "0: 384x640 1 number_plate, 14.6ms\n",
      "Speed: 0.0ms preprocess, 14.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Encoded label: tensor([[ 0, 35, 44,  9, 11, 78,  3, 10,  9,  8,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]], device='cuda:0')\n",
      "Prediction: ['77777777777777777777777777'], Ground Truth: 경기79바1876\n",
      "\n",
      "0: 480x640 1 number_plate, 0.0ms\n",
      "Speed: 0.0ms preprocess, 0.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Encoded label: tensor([[ 0, 35, 44, 10,  3, 78,  6, 11,  7,  2,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]], device='cuda:0')\n",
      "Prediction: ['77777777777777777777777777'], Ground Truth: 경기81바4950\n",
      "\n",
      "0: 288x640 1 number_plate, 0.0ms\n",
      "Speed: 0.0ms preprocess, 0.0ms inference, 0.0ms postprocess per image at shape (1, 3, 288, 640)\n",
      "Encoded label: tensor([[ 0, 35, 44, 10,  5, 79,  3,  9, 11,  5,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]], device='cuda:0')\n",
      "Prediction: ['77777777777777777777777777'], Ground Truth: 경기83배1793\n",
      "\n",
      "0: 416x640 1 number_plate, 0.0ms\n",
      "Speed: 15.7ms preprocess, 0.0ms inference, 12.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "Encoded label: tensor([[ 0, 35, 44, 10,  7, 78,  9, 10,  5,  4,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]], device='cuda:0')\n",
      "Prediction: ['77777777777777777777777777'], Ground Truth: 경기85바7832\n",
      "\n",
      "0: 512x640 1 number_plate, 16.6ms\n",
      "Speed: 0.0ms preprocess, 16.6ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Encoded label: tensor([[ 0, 35, 44, 10, 11, 97,  6,  9,  3,  2,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]], device='cuda:0')\n",
      "Prediction: ['7777777[s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s]'], Ground Truth: 경기89아4710\n",
      "\n",
      "0: 288x640 1 number_plate, 16.7ms\n",
      "Speed: 0.0ms preprocess, 16.7ms inference, 0.0ms postprocess per image at shape (1, 3, 288, 640)\n",
      "Encoded label: tensor([[  0,  35,  44,  11,   2, 117,   6,   3,  10,   3,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]], device='cuda:0')\n",
      "Prediction: ['777777[s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s]'], Ground Truth: 경기90자4181\n",
      "\n",
      "0: 320x640 1 number_plate, 15.8ms\n",
      "Speed: 0.0ms preprocess, 15.8ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Encoded label: tensor([[ 0, 35, 44, 11,  3, 78,  9,  7,  5,  5,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]], device='cuda:0')\n",
      "Prediction: ['기7777[s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s]'], Ground Truth: 경기91바7533\n",
      "\n",
      "0: 576x640 1 number_plate, 3.2ms\n",
      "Speed: 15.5ms preprocess, 3.2ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "Encoded label: tensor([[  0,  35,  44,  11,   3, 117,   8,  11,  10,   5,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]], device='cuda:0')\n",
      "Prediction: ['기777[s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s]'], Ground Truth: 경기91자6983\n",
      "\n",
      "0: 384x640 1 number_plate, 0.0ms\n",
      "Speed: 15.6ms preprocess, 0.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Encoded label: tensor([[  0,  35,  44,  11,   3, 117,   9,   9,   4,   9,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]], device='cuda:0')\n",
      "Prediction: ['기777[s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s]'], Ground Truth: 경기91자7727\n",
      "\n",
      "0: 256x640 1 number_plate, 15.6ms\n",
      "Speed: 0.0ms preprocess, 15.6ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 640)\n",
      "Encoded label: tensor([[ 0, 35, 44, 11,  4, 78,  8,  8,  3,  3,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]], device='cuda:0')\n",
      "Prediction: ['기777[s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s]'], Ground Truth: 경기92바6611\n",
      "\n",
      "0: 448x640 1 number_plate, 2.6ms\n",
      "Speed: 1.0ms preprocess, 2.6ms inference, 0.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Encoded label: tensor([[ 0, 35, 44, 11,  5, 67,  5,  9,  3,  5,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]], device='cuda:0')\n",
      "Prediction: ['기777[s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s]'], Ground Truth: 경기93루3713\n",
      "\n",
      "0: 384x640 1 number_plate, 15.0ms\n",
      "Speed: 0.0ms preprocess, 15.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Encoded label: tensor([[ 0, 35, 44, 11,  5, 97,  4, 11,  5,  2,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]], device='cuda:0')\n",
      "Prediction: ['기기71[s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s]'], Ground Truth: 경기93아2930\n",
      "\n",
      "0: 416x640 1 number_plate, 0.0ms\n",
      "Speed: 15.1ms preprocess, 0.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "Encoded label: tensor([[  0,  35,  44,  11,   5, 117,  10,   6,  10,   9,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]], device='cuda:0')\n",
      "Prediction: ['기기71[s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s]'], Ground Truth: 경기93자8487\n",
      "\n",
      "0: 384x640 1 number_plate, 15.9ms\n",
      "Speed: 0.0ms preprocess, 15.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Encoded label: tensor([[ 0, 35, 44, 11,  6, 97,  4,  9,  6,  9,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]], device='cuda:0')\n",
      "Prediction: ['기기71[s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s]'], Ground Truth: 경기94아2747\n",
      "\n",
      "0: 480x640 1 number_plate, 0.0ms\n",
      "Speed: 0.0ms preprocess, 0.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Encoded label: tensor([[  0,  35,  44,  11,   6, 117,  10,   9,   4,   5,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]], device='cuda:0')\n",
      "Prediction: ['기기733[s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s]'], Ground Truth: 경기94자8723\n",
      "\n",
      "0: 416x640 1 number_plate, 0.0ms\n",
      "Speed: 0.0ms preprocess, 0.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "Encoded label: tensor([[ 0, 35, 44, 11,  7, 87,  4,  5,  3,  5,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]], device='cuda:0')\n",
      "Prediction: ['기기733[s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s]'], Ground Truth: 경기95사2313\n",
      "\n",
      "0: 448x640 1 number_plate, 14.6ms\n",
      "Speed: 0.0ms preprocess, 14.6ms inference, 0.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Encoded label: tensor([[  0,  35,  44,  11,   7, 117,   7,   8,   4,   9,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]], device='cuda:0')\n",
      "Prediction: ['기기733[s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s]'], Ground Truth: 경기95자5627\n",
      "\n",
      "0: 576x640 1 number_plate, 15.8ms\n",
      "Speed: 0.0ms preprocess, 15.8ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "Encoded label: tensor([[ 0, 35, 44, 11, 10, 78,  5,  9,  9,  8,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]], device='cuda:0')\n",
      "Prediction: ['기기733[s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s]'], Ground Truth: 경기98바3776\n",
      "\n",
      "0: 448x640 1 number_plate, 0.0ms\n",
      "Speed: 15.7ms preprocess, 0.0ms inference, 0.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Encoded label: tensor([[ 0, 35, 44, 11, 11, 87, 10,  5,  3,  8,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]], device='cuda:0')\n",
      "Prediction: ['경기733[s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s]'], Ground Truth: 경기99사8316\n",
      "\n",
      "0: 416x640 1 number_plate, 16.4ms\n",
      "Speed: 0.0ms preprocess, 16.4ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "Encoded label: tensor([[ 0, 35, 48, 10,  3, 87, 11,  9,  8,  9,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]], device='cuda:0')\n",
      "Prediction: ['경기733[s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s]'], Ground Truth: 경남81사9767\n",
      "\n",
      "0: 416x640 1 number_plate, 0.0ms\n",
      "Speed: 0.0ms preprocess, 0.0ms inference, 15.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "Encoded label: tensor([[ 0, 35, 48, 10,  3, 87, 11,  9,  8,  9,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]], device='cuda:0')\n",
      "Prediction: ['경기733[s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s]'], Ground Truth: 경남81사9767\n",
      "\n",
      "0: 448x640 1 number_plate, 5.6ms\n",
      "Speed: 12.0ms preprocess, 5.6ms inference, 0.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Encoded label: tensor([[ 0, 35, 48, 10,  4, 87,  4, 10,  4,  4,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]], device='cuda:0')\n",
      "Prediction: ['경기733[s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s]'], Ground Truth: 경남82사2822\n",
      "\n",
      "0: 256x640 1 number_plate, 0.0ms\n",
      "Speed: 0.0ms preprocess, 0.0ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 640)\n",
      "Encoded label: tensor([[ 0, 35, 85, 10,  8, 97, 11,  9,  8, 11,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]], device='cuda:0')\n",
      "Prediction: ['경기733[s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s]'], Ground Truth: 경북86아9769\n",
      "\n",
      "0: 416x640 1 number_plate, 0.0ms\n",
      "Speed: 0.0ms preprocess, 0.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "Encoded label: tensor([[  0,  40, 124,  10,   4,  78,   3,   8,   6,   3,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]], device='cuda:0')\n",
      "Prediction: ['경기779[s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s]'], Ground Truth: 광주82바1641\n",
      "\n",
      "0: 448x640 1 number_plate, 15.1ms\n",
      "Speed: 0.0ms preprocess, 15.1ms inference, 0.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Encoded label: tensor([[  0,  40, 124,  10,   8,  78,   8,  11,   9,   2,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]], device='cuda:0')\n",
      "Prediction: ['경기7999[s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s]'], Ground Truth: 광주86바6970\n",
      "\n",
      "0: 352x640 1 number_plate, 15.1ms\n",
      "Speed: 0.0ms preprocess, 15.1ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "Encoded label: tensor([[  0,  40, 124,  10,   8,  78,   8,  11,   9,   2,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]], device='cuda:0')\n",
      "Prediction: ['경기799999[s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s]'], Ground Truth: 광주86바6970\n",
      "\n",
      "0: 416x640 1 number_plate, 17.1ms\n",
      "Speed: 0.0ms preprocess, 17.1ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "Encoded label: tensor([[  0,  40, 124,  10,   8,  78,   8,  11,   9,   2,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]], device='cuda:0')\n",
      "Prediction: ['경기7999999[s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s]'], Ground Truth: 광주86바6970\n",
      "\n",
      "0: 416x640 1 number_plate, 15.0ms\n",
      "Speed: 0.0ms preprocess, 15.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "Encoded label: tensor([[  0,  40, 124,  10,   8,  78,   8,  11,   9,   2,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]], device='cuda:0')\n",
      "Prediction: ['경기79999999[s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s]'], Ground Truth: 광주86바6970\n",
      "\n",
      "0: 448x640 1 number_plate, 6.2ms\n",
      "Speed: 11.7ms preprocess, 6.2ms inference, 0.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Encoded label: tensor([[  0,  40, 124,  10,   8,  78,   8,  11,   9,   2,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]], device='cuda:0')\n",
      "Prediction: ['경기79999999[s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s]'], Ground Truth: 광주86바6970\n",
      "\n",
      "0: 448x640 1 number_plate, 16.0ms\n",
      "Speed: 0.0ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Encoded label: tensor([[  0,  40, 124,  10,   8,  78,   8,  11,   9,   2,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]], device='cuda:0')\n",
      "Prediction: ['경기99999999[s]9[s][s][s][s][s][s][s][s][s][s][s][s][s][s]'], Ground Truth: 광주86바6970\n",
      "\n",
      "0: 416x640 1 number_plate, 0.0ms\n",
      "Speed: 0.0ms preprocess, 0.0ms inference, 15.7ms postprocess per image at shape (1, 3, 416, 640)\n",
      "Encoded label: tensor([[  0,  40, 124,  10,   8,  78,  10,   2,   3,   2,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]], device='cuda:0')\n",
      "Prediction: ['경기99999999[s]9[s][s][s][s][s][s][s][s][s][s][s][s][s][s]'], Ground Truth: 광주86바8010\n",
      "\n",
      "0: 416x640 1 number_plate, 0.6ms\n",
      "Speed: 15.9ms preprocess, 0.6ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "Encoded label: tensor([[  0,  40, 124,  11,   2,  78,   8,   5,   4,  10,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]], device='cuda:0')\n",
      "Prediction: ['경기9999999[s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s]'], Ground Truth: 광주90바6328\n",
      "\n",
      "0: 320x640 1 number_plate, 7.0ms\n",
      "Speed: 12.1ms preprocess, 7.0ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Encoded label: tensor([[  0,  55,  42,  10,   3, 117,   5,   2,   7,  10,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]], device='cuda:0')\n",
      "Prediction: ['경기99999[s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s]'], Ground Truth: 대구81자3058\n",
      "\n",
      "0: 512x640 1 number_plate, 0.0ms\n",
      "Speed: 0.0ms preprocess, 0.0ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Encoded label: tensor([[ 0, 55, 42, 10,  5, 97, 11,  9,  3,  6,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]], device='cuda:0')\n",
      "Prediction: ['경기99999[s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s]'], Ground Truth: 대구83아9714\n",
      "\n",
      "0: 448x640 1 number_plate, 0.0ms\n",
      "Speed: 0.0ms preprocess, 0.0ms inference, 0.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Encoded label: tensor([[  0,  55,  42,  89, 141,   7,   3,  10,   7,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]], device='cuda:0')\n",
      "Prediction: ['경기66666[s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s]'], Ground Truth: 대구서하5185\n",
      "\n",
      "0: 384x640 1 number_plate, 0.0ms\n",
      "Speed: 0.0ms preprocess, 0.0ms inference, 14.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Encoded label: tensor([[  0,  55, 120,  10,   9,  97,   3,   3,   8,   5,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]], device='cuda:0')\n",
      "Prediction: ['경기666666[s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s]'], Ground Truth: 대전87아1163\n",
      "\n",
      "0: 416x640 1 number_plate, 0.0ms\n",
      "Speed: 0.7ms preprocess, 0.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "Encoded label: tensor([[  0,  55, 120,  10,   9,  97,  10,  10,   3,   5,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]], device='cuda:0')\n",
      "Prediction: ['경기6666666[s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s]'], Ground Truth: 대전87아8813\n",
      "\n",
      "0: 384x640 1 number_plate, 15.2ms\n",
      "Speed: 0.0ms preprocess, 15.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Encoded label: tensor([[  0,  89, 109,   5,   3,  87,   3,   5,   6,   2,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]], device='cuda:0')\n",
      "Prediction: ['경기86666666666[s][s][s][s][s][s][s][s][s][s][s][s][s]'], Ground Truth: 서울31사1340\n",
      "\n",
      "0: 256x640 1 number_plate, 0.0ms\n",
      "Speed: 0.0ms preprocess, 0.0ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 640)\n",
      "Encoded label: tensor([[  0,  89, 109,   5,   3, 117,   3,   6,   3,   6,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]], device='cuda:0')\n",
      "Prediction: ['경8866666666666666666666666'], Ground Truth: 서울31자1414\n",
      "\n",
      "0: 352x640 1 number_plate, 0.0ms\n",
      "Speed: 0.0ms preprocess, 0.0ms inference, 15.1ms postprocess per image at shape (1, 3, 352, 640)\n",
      "Encoded label: tensor([[  0,  89, 109,   5,   5,  78,   9,   3,  10,   3,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]], device='cuda:0')\n",
      "Prediction: ['경8886666666[s][s][s][s][s][s][s][s][s][s][s][s][s][s][s]'], Ground Truth: 서울33바7181\n",
      "\n",
      "0: 256x640 1 number_plate, 15.7ms\n",
      "Speed: 0.0ms preprocess, 15.7ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 640)\n",
      "Encoded label: tensor([[  0,  89, 109,   5,   5,  87,   5,   2,   5,   8,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]], device='cuda:0')\n",
      "Prediction: ['경8888666[s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s]'], Ground Truth: 서울33사3036\n",
      "\n",
      "0: 384x640 1 number_plate, 15.7ms\n",
      "Speed: 0.0ms preprocess, 15.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Encoded label: tensor([[  0,  89, 109,   5,   5,  97,   4,   2,   8,   5,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]], device='cuda:0')\n",
      "Prediction: ['경8888886[s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s]'], Ground Truth: 서울33아2063\n",
      "\n",
      "0: 448x640 1 number_plate, 16.3ms\n",
      "Speed: 0.0ms preprocess, 16.3ms inference, 0.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Encoded label: tensor([[  0,  89, 109,   6,   9,  71,   7,   5,   6,   6,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]], device='cuda:0')\n",
      "Prediction: ['경8888888[s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s]'], Ground Truth: 서울47머5344\n",
      "\n",
      "0: 576x640 1 number_plate, 4.8ms\n",
      "Speed: 8.8ms preprocess, 4.8ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "Encoded label: tensor([[  0,  89, 109,   8,  10,  78,   7,   6,   6,   2,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]], device='cuda:0')\n",
      "Prediction: ['경888888[s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s]'], Ground Truth: 서울68바5440\n",
      "\n",
      "0: 480x640 1 number_plate, 15.1ms\n",
      "Speed: 0.0ms preprocess, 15.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Encoded label: tensor([[  0,  89, 109,   9,   6,  78,   3,   9,   6,   4,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]], device='cuda:0')\n",
      "Prediction: ['경888888[s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s]'], Ground Truth: 서울74바1742\n",
      "\n",
      "0: 416x640 1 number_plate, 13.2ms\n",
      "Speed: 0.0ms preprocess, 13.2ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "Encoded label: tensor([[  0,  89, 109,   9,   6,  87,   6,  10,   2,   5,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]], device='cuda:0')\n",
      "Prediction: ['경88881[s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s]'], Ground Truth: 서울74사4803\n",
      "\n",
      "0: 448x640 1 number_plate, 12.8ms\n",
      "Speed: 0.0ms preprocess, 12.8ms inference, 0.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Encoded label: tensor([[  0,  89, 109,   9,   7,  87,   3,   6,   4,   9,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]], device='cuda:0')\n",
      "Prediction: ['경88881[s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s]'], Ground Truth: 서울75사1427\n",
      "\n",
      "0: 256x640 1 number_plate, 16.5ms\n",
      "Speed: 0.0ms preprocess, 16.5ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 640)\n",
      "Encoded label: tensor([[  0,  89, 109,  10,   2,  79,   4,  10,   8,  10,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]], device='cuda:0')\n",
      "Prediction: ['경기8811[s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s]'], Ground Truth: 서울80배2868\n",
      "\n",
      "0: 448x640 1 number_plate, 18.2ms\n",
      "Speed: 0.0ms preprocess, 18.2ms inference, 0.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Encoded label: tensor([[  0,  89, 109,  10,   5,  78,   7,   8,   8,   9,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]], device='cuda:0')\n",
      "Prediction: ['경38811[s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s]'], Ground Truth: 서울83바5667\n",
      "\n",
      "0: 256x640 1 number_plate, 15.7ms\n",
      "Speed: 0.0ms preprocess, 15.7ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 640)\n",
      "Encoded label: tensor([[  0,  89, 109,  10,   5,  87,   6,   8,  11,   7,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]], device='cuda:0')\n",
      "Prediction: ['경3881[s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s]'], Ground Truth: 서울83사4695\n",
      "\n",
      "0: 320x640 1 number_plate, 15.1ms\n",
      "Speed: 0.0ms preprocess, 15.1ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Encoded label: tensor([[  0,  89, 109,  10,   5, 117,   9,   6,   2,  11,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]], device='cuda:0')\n",
      "Prediction: ['경3881[s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s]'], Ground Truth: 서울83자7409\n",
      "\n",
      "0: 288x640 1 number_plate, 16.0ms\n",
      "Speed: 0.0ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 288, 640)\n",
      "Encoded label: tensor([[  0,  89, 109,  10,   5, 117,   9,   6,   2,  11,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]], device='cuda:0')\n",
      "Prediction: ['경3881[s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s]'], Ground Truth: 서울83자7409\n",
      "\n",
      "0: 512x640 1 number_plate, 0.0ms\n",
      "Speed: 0.0ms preprocess, 0.0ms inference, 15.6ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Encoded label: tensor([[  0,  89, 109,  10,   7,  54,   5,  11,   5,   6,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]], device='cuda:0')\n",
      "Prediction: ['경3881[s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s]'], Ground Truth: 서울85다3934\n",
      "\n",
      "0: 608x640 1 number_plate, 0.0ms\n",
      "Speed: 15.1ms preprocess, 0.0ms inference, 0.0ms postprocess per image at shape (1, 3, 608, 640)\n",
      "Encoded label: tensor([[  0,  89, 109,  10,   7,  78,   7,   2,  10,   9,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]], device='cuda:0')\n",
      "Prediction: ['경3383[s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s]'], Ground Truth: 서울85바5087\n",
      "\n",
      "0: 384x640 1 number_plate, 0.0ms\n",
      "Speed: 15.7ms preprocess, 0.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Encoded label: tensor([[  0,  89, 109,  10,   8,  78,   7,   7,   8,  10,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]], device='cuda:0')\n",
      "Prediction: ['경3333[s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s]'], Ground Truth: 서울86바5568\n",
      "\n",
      "0: 416x640 1 number_plate, 15.7ms\n",
      "Speed: 0.0ms preprocess, 15.7ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "Encoded label: tensor([[  0,  89, 109,  10,  10,  78,  11,   5,   2,   2,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]], device='cuda:0')\n",
      "Prediction: ['경3333[s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s]'], Ground Truth: 서울88바9300\n",
      "\n",
      "0: 416x640 1 number_plate, 0.0ms\n",
      "Speed: 15.6ms preprocess, 0.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "Encoded label: tensor([[  0,  89, 109,  10,  11, 117,   6,   4,   9,   5,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]], device='cuda:0')\n",
      "Prediction: ['경3333[s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s]'], Ground Truth: 서울89자4273\n",
      "\n",
      "0: 512x640 1 number_plate, 0.0ms\n",
      "Speed: 0.0ms preprocess, 0.0ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Encoded label: tensor([[  0,  89, 109,  10,  11, 117,   9,   7,  10,   7,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]], device='cuda:0')\n",
      "Prediction: ['경3833[s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s]'], Ground Truth: 서울89자7585\n",
      "\n",
      "0: 544x640 1 number_plate, 13.9ms\n",
      "Speed: 0.0ms preprocess, 13.9ms inference, 0.0ms postprocess per image at shape (1, 3, 544, 640)\n",
      "Encoded label: tensor([[  0,  89, 109,  11,   2,  78,   3,   4,   3,   7,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]], device='cuda:0')\n",
      "Prediction: ['경3883[s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s]'], Ground Truth: 서울90바1215\n",
      "\n",
      "0: 512x640 1 number_plate, 13.1ms\n",
      "Speed: 0.0ms preprocess, 13.1ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Encoded label: tensor([[  0,  89, 109,  11,   2,  78,   6,   8,  10,   6,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]], device='cuda:0')\n",
      "Prediction: ['경88833[s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s]'], Ground Truth: 서울90바4684\n",
      "\n",
      "0: 416x640 1 number_plate, 13.6ms\n",
      "Speed: 0.0ms preprocess, 13.6ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "Encoded label: tensor([[  0,  89, 109,  11,   2,  78,   7,   2,  10,   6,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]], device='cuda:0')\n",
      "Prediction: ['경8883[s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s]'], Ground Truth: 서울90바5084\n",
      "\n",
      "0: 416x640 1 number_plate, 12.5ms\n",
      "Speed: 0.0ms preprocess, 12.5ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "Encoded label: tensor([[  0,  89, 109,  11,   3, 117,   3,   6,   3,   7,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]], device='cuda:0')\n",
      "Prediction: ['경8888[s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s]'], Ground Truth: 서울91자1415\n",
      "\n",
      "0: 256x640 1 number_plate, 0.0ms\n",
      "Speed: 0.0ms preprocess, 0.0ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 640)\n",
      "Encoded label: tensor([[  0,  89, 109,  11,  10,  78,   5,   9,   4,   3,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]], device='cuda:0')\n",
      "Prediction: ['경8888[s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s]'], Ground Truth: 서울98바3721\n",
      "\n",
      "0: 256x640 1 number_plate, 12.8ms\n",
      "Speed: 0.0ms preprocess, 12.8ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 640)\n",
      "Encoded label: tensor([[  0,  89, 109,  11,  10,  78,   5,   9,   4,   3,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]], device='cuda:0')\n",
      "Prediction: ['경8888[s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s]'], Ground Truth: 서울98바3721\n",
      "\n",
      "0: 256x640 1 number_plate, 0.0ms\n",
      "Speed: 0.0ms preprocess, 0.0ms inference, 15.1ms postprocess per image at shape (1, 3, 256, 640)\n",
      "Encoded label: tensor([[  0,  89, 109,  11,  10,  78,   6,   8,   9,   8,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]], device='cuda:0')\n",
      "Prediction: ['경8888[s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s]'], Ground Truth: 서울98바4676\n",
      "\n",
      "0: 448x640 1 number_plate, 0.0ms\n",
      "Speed: 0.0ms preprocess, 0.0ms inference, 0.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Encoded label: tensor([[  0,  89, 109,  11,  10,  78,  10,   8,  11,  10,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]], device='cuda:0')\n",
      "Prediction: ['경88888[s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s]'], Ground Truth: 서울98바8698\n",
      "\n",
      "0: 416x640 1 number_plate, 14.5ms\n",
      "Speed: 0.0ms preprocess, 14.5ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "Encoded label: tensor([[  0,  89, 109,  11,  10,  78,  10,   8,  11,  10,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]], device='cuda:0')\n",
      "Prediction: ['경88888[s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s]'], Ground Truth: 서울98바8698\n",
      "\n",
      "0: 544x640 2 number_plates, 20.1ms\n",
      "Speed: 0.0ms preprocess, 20.1ms inference, 0.0ms postprocess per image at shape (1, 3, 544, 640)\n",
      "Encoded label: tensor([[  0,  89, 109,  11,  10,  87,   7,  11,   7,   7,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]], device='cuda:0')\n",
      "Prediction: ['경88888[s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s]'], Ground Truth: 서울98사5955\n",
      "\n",
      "0: 512x640 1 number_plate, 0.0ms\n",
      "Speed: 0.0ms preprocess, 0.0ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Encoded label: tensor([[  0,  89, 109,  27,  48, 137,  11,   6,  11,   4,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]], device='cuda:0')\n",
      "Prediction: ['경888888[s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s]'], Ground Truth: 서울강남타9492\n",
      "\n",
      "0: 576x640 1 number_plate, 0.0ms\n",
      "Speed: 15.1ms preprocess, 0.0ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "Encoded label: tensor([[  0,  89, 109,  27,  48, 141,   8,   4,   3,   2,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]], device='cuda:0')\n",
      "Prediction: ['경888888[s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s]'], Ground Truth: 서울강남하6210\n",
      "\n",
      "0: 512x640 1 number_plate, 13.6ms\n",
      "Speed: 0.0ms preprocess, 13.6ms inference, 2.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Encoded label: tensor([[  0,  89, 109,  27,  89, 117,  10,  10,   9,  11,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]], device='cuda:0')\n",
      "Prediction: ['경888888[s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s]'], Ground Truth: 서울강서자8879\n",
      "\n",
      "0: 416x640 1 number_plate, 15.7ms\n",
      "Speed: 0.0ms preprocess, 15.7ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "Encoded label: tensor([[  0,  89, 109,  27,  89, 117,  10,  10,   9,  11,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]], device='cuda:0')\n",
      "Prediction: ['경8888888[s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s]'], Ground Truth: 서울강서자8879\n",
      "\n",
      "0: 576x640 1 number_plate, 21.0ms\n",
      "Speed: 0.0ms preprocess, 21.0ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "Encoded label: tensor([[  0,  89, 109,  43, 129, 117,   4,   3,   5,   6,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]], device='cuda:0')\n",
      "Prediction: ['경8888888[s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s]'], Ground Truth: 서울금천자2134\n",
      "\n",
      "0: 384x640 1 number_plate, 0.0ms\n",
      "Speed: 15.6ms preprocess, 0.0ms inference, 13.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Encoded label: tensor([[  0,  89, 109,  43, 129, 117,   8,   2,  10,   2,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]], device='cuda:0')\n",
      "Prediction: ['경울888888[s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s]'], Ground Truth: 서울금천자6080\n",
      "\n",
      "0: 384x640 1 number_plate, 0.0ms\n",
      "Speed: 15.7ms preprocess, 0.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Encoded label: tensor([[  0, 116, 129,   9,   2,  78,   5,   7,   2,   7,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]], device='cuda:0')\n",
      "Prediction: ['경888888[s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s]'], Ground Truth: 인천70바3505\n",
      "\n",
      "0: 384x640 1 number_plate, 0.0ms\n",
      "Speed: 0.0ms preprocess, 0.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Encoded label: tensor([[  0, 116, 129,   9,   3,  78,   8,   3,   8,   6,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]], device='cuda:0')\n",
      "Prediction: ['경울88888[s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s]'], Ground Truth: 인천71바6164\n",
      "\n",
      "0: 416x640 1 number_plate, 15.6ms\n",
      "Speed: 0.0ms preprocess, 15.6ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "Encoded label: tensor([[  0, 116, 129,   9,   4,  78,   3,   9,  10,   6,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]], device='cuda:0')\n",
      "Prediction: ['경울88888[s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s]'], Ground Truth: 인천72바1784\n",
      "\n",
      "0: 416x640 1 number_plate, 0.0ms\n",
      "Speed: 0.8ms preprocess, 0.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "Encoded label: tensor([[  0, 116, 129,   9,   4,  78,   3,   9,  11,   7,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]], device='cuda:0')\n",
      "Prediction: ['경울8888[s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s]'], Ground Truth: 인천72바1795\n",
      "\n",
      "0: 416x640 1 number_plate, 9.8ms\n",
      "Speed: 3.1ms preprocess, 9.8ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "Encoded label: tensor([[  0, 116, 129,   9,  10,  78,   3,   3,   6,   7,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]], device='cuda:0')\n",
      "Prediction: ['경울울8888[s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s]'], Ground Truth: 인천78바1145\n",
      "\n",
      "0: 448x640 1 number_plate, 15.8ms\n",
      "Speed: 0.0ms preprocess, 15.8ms inference, 0.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Encoded label: tensor([[  0, 116, 129,  10,   4,  78,   6,   6,   9,   4,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]], device='cuda:0')\n",
      "Prediction: ['경울울8888[s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s]'], Ground Truth: 인천82바4472\n",
      "\n",
      "0: 384x640 1 number_plate, 0.0ms\n",
      "Speed: 0.0ms preprocess, 0.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Encoded label: tensor([[  0, 116, 129,  10,   7,  78,   3,   6,  10,   4,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]], device='cuda:0')\n",
      "Prediction: ['경울울8888[s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s]'], Ground Truth: 인천85바1482\n",
      "\n",
      "0: 416x640 1 number_plate, 0.0ms\n",
      "Speed: 0.0ms preprocess, 0.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "Encoded label: tensor([[  0, 116, 129,  10,   7,  79,   3,   6,  11,  10,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]], device='cuda:0')\n",
      "Prediction: ['경울울8888[s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s]'], Ground Truth: 인천85배1498\n",
      "\n",
      "0: 576x640 1 number_plate, 0.0ms\n",
      "Speed: 15.7ms preprocess, 0.0ms inference, 9.6ms postprocess per image at shape (1, 3, 576, 640)\n",
      "Encoded label: tensor([[  0, 116, 129,  10,   7,  87,   3,  10,   8,   2,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]], device='cuda:0')\n",
      "Prediction: ['경울울8888[s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s]'], Ground Truth: 인천85사1860\n",
      "\n",
      "0: 416x640 1 number_plate, 13.9ms\n",
      "Speed: 0.0ms preprocess, 13.9ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "Encoded label: tensor([[  0, 116, 129,  10,   7,  97,   3,   9,   6,   6,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]], device='cuda:0')\n",
      "Prediction: ['경울울8888[s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s]'], Ground Truth: 인천85아1744\n",
      "\n",
      "0: 288x640 1 number_plate, 15.1ms\n",
      "Speed: 0.0ms preprocess, 15.1ms inference, 0.0ms postprocess per image at shape (1, 3, 288, 640)\n",
      "Encoded label: tensor([[  0, 116, 129,  10,   8,  78,  11,   4,   5,  10,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]], device='cuda:0')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 221\u001b[0m\n\u001b[0;32m    218\u001b[0m     str_model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m    220\u001b[0m \u001b[38;5;66;03m# 트레이닝 실행\u001b[39;00m\n\u001b[1;32m--> 221\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[2], line 172\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(opt)\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncoded label: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    171\u001b[0m \u001b[38;5;66;03m# 모델 예측 (Attn 모델이므로 text[:, :-1] 사용)\u001b[39;00m\n\u001b[1;32m--> 172\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[43mstr_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mplate_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;66;03m# 예측된 시퀀스 디코딩\u001b[39;00m\n\u001b[0;32m    175\u001b[0m _, preds_index \u001b[38;5;241m=\u001b[39m preds\u001b[38;5;241m.\u001b[39mmax(\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\KD7-3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\KD7-3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mD:\\KD7-3\\DataProject\\lincenseplateocr\\model.py:101\u001b[0m, in \u001b[0;36mModel.forward\u001b[1;34m(self, input, text, is_train)\u001b[0m\n\u001b[0;32m     99\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mPrediction(contextual_feature\u001b[38;5;241m.\u001b[39mcontiguous())\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 101\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPrediction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontextual_feature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m prediction\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\KD7-3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\KD7-3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mD:\\KD7-3\\DataProject\\lincenseplateocr\\modules\\prediction.py:44\u001b[0m, in \u001b[0;36mAttention.forward\u001b[1;34m(self, batch_H, text, is_train, batch_max_length)\u001b[0m\n\u001b[0;32m     42\u001b[0m     char_onehots \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_char_to_onehot(text[:, i], onehot_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_classes)\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;66;03m# hidden : decoder's hidden s_{t-1}, batch_H : encoder's hidden H, char_onehots : one-hot(y_{t-1})\u001b[39;00m\n\u001b[1;32m---> 44\u001b[0m     hidden, alpha \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention_cell\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_H\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchar_onehots\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m     output_hiddens[:, i, :] \u001b[38;5;241m=\u001b[39m hidden[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# LSTM hidden index (0: hidden, 1: Cell)\u001b[39;00m\n\u001b[0;32m     46\u001b[0m probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerator(output_hiddens)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\KD7-3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\KD7-3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mD:\\KD7-3\\DataProject\\lincenseplateocr\\modules\\prediction.py:75\u001b[0m, in \u001b[0;36mAttentionCell.forward\u001b[1;34m(self, prev_hidden, batch_H, char_onehots)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, prev_hidden, batch_H, char_onehots):\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;66;03m# [batch_size x num_encoder_step x num_channel] -> [batch_size x num_encoder_step x hidden_size]\u001b[39;00m\n\u001b[1;32m---> 75\u001b[0m     batch_H_proj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mi2h\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_H\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     76\u001b[0m     prev_hidden_proj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mh2h(prev_hidden[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     77\u001b[0m     e \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscore(torch\u001b[38;5;241m.\u001b[39mtanh(batch_H_proj \u001b[38;5;241m+\u001b[39m prev_hidden_proj))  \u001b[38;5;66;03m# batch_size x num_encoder_step * 1\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\KD7-3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\KD7-3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\KD7-3\\lib\\site-packages\\torch\\nn\\modules\\linear.py:117\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torch.utils.data\n",
    "from torchvision import transforms\n",
    "from PIL import Image, ImageDraw\n",
    "from lincenseplateocr.model import Model\n",
    "from lincenseplateocr.utils import AttnLabelConverter, CTCLabelConverter\n",
    "from lincenseplateocr.dataset import AlignCollate, hierarchical_dataset\n",
    "from lincenseplateocr.test import validation\n",
    "from ultralytics import YOLO  # YOLO 모델 추가\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class Options:\n",
    "    def __init__(self):\n",
    "        self.exp_name = 'license_plate_training'\n",
    "        self.train_data = 'lincenseplateocr/input/train'\n",
    "        self.valid_data = 'lincenseplateocr/input/vali'\n",
    "        self.saved_model = 'lincenseplateocr/pretrained/Fine-Tuned.pth'\n",
    "        self.num_iter = 3000\n",
    "        self.valInterval = 1\n",
    "        self.batch_size = 1000\n",
    "        torch.cuda.empty_cache()\n",
    "        self.lr = 0.001\n",
    "        self.beta1 = 0.9\n",
    "        self.eps = 1e-8\n",
    "        self.Prediction = 'Attn'\n",
    "        self.batch_max_length = 25\n",
    "        self.imgH = 32\n",
    "        self.imgW = 100\n",
    "        self.character = '0123456789().JNRW_abcdef가강개걍거겅겨견결경계고과관광굥구금기김깅나남너노논누니다대댜더뎡도동두등디라러로루룰리마머명모무문므미바배뱌버베보부북비사산서성세셔소송수시아악안양어여연영오올용우울원육으을이익인자작저전제조종주중지차처천초추출충층카콜타파평포하허호홀후히ㅣ'\n",
    "        self.input_channel = 1\n",
    "        self.output_channel = 512\n",
    "        self.hidden_size = 256\n",
    "        self.workers = 0\n",
    "        self.FT = True\n",
    "        self.Transformation = 'TPS'\n",
    "        self.FeatureExtraction = 'ResNet'\n",
    "        self.SequenceModeling = 'BiLSTM'\n",
    "        self.num_fiducial = 20\n",
    "        self.data_filtering_off = False\n",
    "        self.rgb = False\n",
    "        self.sensitive = False\n",
    "\n",
    "opt = Options()\n",
    "\n",
    "# STR 모델 준비\n",
    "if opt.Prediction == 'Attn':\n",
    "    converter = AttnLabelConverter(opt.character)\n",
    "else:\n",
    "    converter = CTCLabelConverter(opt.character)\n",
    "opt.num_class = len(converter.character)\n",
    "print(f\"Using converter: {type(converter)}\")\n",
    "\n",
    "# 모델 로드 부분 수정\n",
    "str_model = Model(opt).to(device)\n",
    "\n",
    "if opt.saved_model != '':\n",
    "    # Fine-tuning 옵션에 따른 requires_grad 설정\n",
    "    if opt.FT:\n",
    "        print(f'Fine-tuning mode: Loading pretrained model for fine-tuning')\n",
    "        str_model.load_state_dict(torch.load(opt.saved_model, map_location=device), strict=False)\n",
    "\n",
    "        # Prediction 레이어 내 모든 파라미터의 requires_grad를 True로 설정\n",
    "        for name, param in str_model.named_parameters():\n",
    "            if 'Prediction' in name:  # Prediction 관련 파라미터만 True로 설정\n",
    "                param.requires_grad = True\n",
    "                print(f'{name} - requires_grad: True')\n",
    "            else:\n",
    "                param.requires_grad = False  # 나머지 레이어는 고정\n",
    "    else:\n",
    "        print(f'Loading pretrained model from {opt.saved_model}')\n",
    "        str_model.load_state_dict(torch.load(opt.saved_model, map_location=device))\n",
    "\n",
    "# 손실 함수 및 옵티마이저 설정\n",
    "criterion = torch.nn.CrossEntropyLoss(ignore_index=0).to(device)\n",
    "\n",
    "# 옵티마이저 설정\n",
    "filtered_parameters = []\n",
    "for p in filter(lambda p: p.requires_grad, str_model.parameters()):\n",
    "    filtered_parameters.append(p)\n",
    "\n",
    "if len(filtered_parameters) == 0:\n",
    "    raise ValueError(\"No parameters available for training. Please check requires_grad settings.\")\n",
    "\n",
    "optimizer = optim.Adam(filtered_parameters, lr=opt.lr, betas=(opt.beta1, 0.999))\n",
    "\n",
    "def load_label_json(label_path):\n",
    "    \"\"\"라벨 JSON 파일을 로드\"\"\"\n",
    "    with open(label_path, 'r', encoding='utf-8') as f:\n",
    "        label_data = json.load(f)\n",
    "    return label_data['value']  # 이미지의 실제 라벨\n",
    "\n",
    "def detect_license_plate_yolo(image, model):\n",
    "    \"\"\"YOLO 모델을 이용해 번호판 탐지\"\"\"\n",
    "    results = model(image)\n",
    "    boxes = results[0].boxes  # 탐지된 바운딩 박스\n",
    "    license_plate_boxes = []\n",
    "    \n",
    "    for box in boxes:\n",
    "        # 번호판 클래스(예: 0)일 때만 처리\n",
    "        if int(box.cls[0]) == 0:  # 번호판 클래스 ID가 0이라고 가정\n",
    "            x_min, y_min, x_max, y_max = map(int, box.xyxy[0].tolist())\n",
    "            license_plate_boxes.append([x_min, y_min, x_max, y_max])\n",
    "\n",
    "    return license_plate_boxes\n",
    "\n",
    "def crop_license_plate(image, boxes):\n",
    "    \"\"\"탐지된 번호판 영역을 자름\"\"\"\n",
    "    cropped_plates = []\n",
    "    for box in boxes:\n",
    "        x_min, y_min, x_max, y_max = box\n",
    "        cropped_plates.append(image.crop((x_min, y_min, x_max, y_max)))\n",
    "    return cropped_plates\n",
    "\n",
    "def train(opt):\n",
    "    \"\"\"STR 모델 학습 루프\"\"\"\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((opt.imgH, opt.imgW)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    total_loss = 0\n",
    "    best_loss = float('inf')\n",
    "\n",
    "    save_dir = \"./saved_models\"\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    # YOLO 번호판 탐지 모델 로드\n",
    "    yolo_model = YOLO('weights/plate_detect.pt')  # 번호판 탐지 모델 경로 지정\n",
    "\n",
    "    for iteration in range(opt.num_iter):\n",
    "        total_loss = 0\n",
    "        for img_file in os.listdir(opt.train_data):\n",
    "            torch.cuda.empty_cache()\n",
    "            if img_file.endswith('.jpg'):\n",
    "                image_path = os.path.join(opt.train_data, img_file)\n",
    "                label_path = os.path.splitext(image_path)[0] + \".json\"\n",
    "\n",
    "                try:\n",
    "                    # 이미지 및 라벨 로드\n",
    "                    image = Image.open(image_path).convert('RGB')  # 원본 이미지를 로드\n",
    "                    label = load_label_json(label_path)\n",
    "\n",
    "                    # 번호판 영역 탐지\n",
    "                    license_plate_boxes = detect_license_plate_yolo(image, yolo_model)\n",
    "                    if len(license_plate_boxes) == 0:\n",
    "                        print(f\"번호판이 탐지되지 않음: {image_path}\")\n",
    "                        continue\n",
    "\n",
    "                    # 번호판 영역 자르기\n",
    "                    cropped_license_plates = crop_license_plate(image, license_plate_boxes)\n",
    "\n",
    "                    # 자른 번호판 중 첫 번째 번호판에 대해 진행\n",
    "                    if len(cropped_license_plates) > 0:\n",
    "                        plate_image = cropped_license_plates[0].convert('L')  # 흑백 변환\n",
    "                        plate_image = transform(plate_image).unsqueeze(0).to(device)  # 텐서로 변환\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"이미지 불러오기 오류: {e} - 파일 경로: {image_path} 라벨 경로 : {label_path}\")\n",
    "                    continue\n",
    "\n",
    "                # 라벨 인코딩\n",
    "                text, length = converter.encode([label], batch_max_length=opt.batch_max_length)\n",
    "                print(f\"Encoded label: {text}\")\n",
    "\n",
    "                # 모델 예측 (Attn 모델이므로 text[:, :-1] 사용)\n",
    "                preds = str_model(plate_image, text[:, :-1])\n",
    "\n",
    "                # 예측된 시퀀스 디코딩\n",
    "                _, preds_index = preds.max(2)\n",
    "                preds_str = converter.decode(preds_index, torch.IntTensor([preds.size(1)] * preds.size(0)))\n",
    "                print(f\"Prediction: {preds_str}, Ground Truth: {label}\")\n",
    "\n",
    "                # 타겟 설정 (라벨에서 [GO] 토큰을 제외한 텍스트)\n",
    "                target = text[:, 1:]  # [GO] 토큰 제외\n",
    "\n",
    "                # 예측된 시퀀스 길이를 타겟 길이에 맞춤\n",
    "                preds = preds[:, :target.size(1), :]\n",
    "\n",
    "                # 손실 계산 (CrossEntropyLoss로 계산)\n",
    "                cost = criterion(preds.view(-1, preds.shape[-1]), target.contiguous().view(-1))\n",
    "\n",
    "                # 손실 역전파 및 옵티마이저 업데이트\n",
    "                optimizer.zero_grad()\n",
    "                cost.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                total_loss += cost.item()\n",
    "\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        print(f\"Epoch [{iteration + 1}/{opt.num_iter}], Total Loss: {total_loss:.4f}, Learning Rate: {current_lr:.6f}\")\n",
    "\n",
    "        if total_loss < best_loss:\n",
    "            best_loss = total_loss\n",
    "            torch.save(str_model.state_dict(), f\"./saved_models/{opt.exp_name}_best.pth\")\n",
    "            print(f\"Best model saved with loss: {best_loss:.4f}\")\n",
    "\n",
    "        print(f\"Model saved for epoch {iteration + 1}\")\n",
    "\n",
    "        if (iteration + 1) % opt.valInterval == 0:\n",
    "            validate(opt)\n",
    "\n",
    "def validate(opt):\n",
    "    \"\"\"검증 루틴\"\"\"\n",
    "    AlignCollate_valid = AlignCollate(imgH=opt.imgH, imgW=opt.imgW, keep_ratio_with_pad=True)\n",
    "    valid_dataset, _ = hierarchical_dataset(root=opt.valid_data, opt=opt)\n",
    "    valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=opt.batch_size, shuffle=True, num_workers=opt.workers, collate_fn=AlignCollate_valid)\n",
    "\n",
    "    str_model.eval()\n",
    "    with torch.no_grad():\n",
    "        valid_loss, valid_accuracy = validation(str_model, criterion, valid_loader, converter, opt)[:2]\n",
    "        print(f\"Validation Loss: {valid_loss:.4f}, Validation Accuracy: {valid_accuracy:.4f}\")\n",
    "    str_model.train()\n",
    "\n",
    "# 트레이닝 실행\n",
    "train(opt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb36306b-e2b5-462c-b5a8-e84b3298e233",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
