{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e052ca-b131-4bd8-9966-303c7ce4a269",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from PIL import Image, ImageEnhance, ImageDraw\n",
    "import numpy as np\n",
    "from CRAFT.craft import CRAFT\n",
    "import CRAFT.craft_utils\n",
    "import CRAFT.imgproc\n",
    "from lincenseplateocr.model import Model\n",
    "from lincenseplateocr.utils import AttnLabelConverter, CTCLabelConverter\n",
    "from lincenseplateocr.dataset import AlignCollate\n",
    "from lincenseplateocr.test import validation\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class Options:\n",
    "    def __init__(self):\n",
    "        self.exp_name = 'license_plate_training'  # 실험 이름\n",
    "        self.train_data = 'lincenseplateocr/input/train'  # 트레이닝 데이터 경로\n",
    "        self.valid_data = 'lincenseplateocr/input/vali'  # 검증 데이터 경로\n",
    "        self.saved_model = 'lincenseplateocr/pretrained/Fine-Tuned.pth'  # STR 모델의 사전 학습된 모델\n",
    "        self.num_iter = 3000  # 학습 반복 횟수\n",
    "        self.valInterval = 200  # 검증 간격\n",
    "        self.batch_size = 1  # 배치 크기\n",
    "        self.lr = 0.001  # 학습률\n",
    "        self.Prediction = 'CTC'  # STR의 예측 모드\n",
    "        self.batch_max_length = 25  # 최대 라벨 길이\n",
    "        self.imgH = 32  # 입력 이미지 높이\n",
    "        self.imgW = 100  # 입력 이미지 너비\n",
    "        self.character = '0123456789가나다라'  # 학습할 문자\n",
    "        self.input_channel = 1  # 입력 채널 (흑백 이미지)\n",
    "        self.output_channel = 512  # 출력 채널 수\n",
    "        self.hidden_size = 256  # LSTM 히든 사이즈\n",
    "        self.trained_craft_model = 'CRAFT/weights/craft_mlt_25k.pth'  # CRAFT 사전 학습된 가중치\n",
    "        self.workers = 0  # 데이터 로더 워커 수\n",
    "\n",
    "opt = Options()\n",
    "\n",
    "# CRAFT 모델 로드\n",
    "craft_net = CRAFT()\n",
    "craft_net.load_state_dict(torch.load(opt.trained_craft_model))\n",
    "craft_net = craft_net.to(device)\n",
    "craft_net.eval()\n",
    "\n",
    "# STR 모델 준비\n",
    "converter = AttnLabelConverter(opt.character) if 'CTC' in opt.Prediction else CTCLabelConverter(opt.character)\n",
    "opt.num_class = len(converter.character)\n",
    "str_model = Model(opt).to(device)\n",
    "str_model.load_state_dict(torch.load(opt.saved_model))\n",
    "\n",
    "# 손실 함수 및 옵티마이저 설정\n",
    "criterion = torch.nn.CTCLoss(zero_infinity=True).to(device)\n",
    "optimizer = optim.Adam(str_model.parameters(), lr=opt.lr)\n",
    "\n",
    "\n",
    "class DataAugmentation:\n",
    "    \"\"\"데이터 증강 클래스: 이미지 손상, 저해상도, 각도 조정, 이미지 일부 가리기\"\"\"\n",
    "    \n",
    "    def __init__(self, imgH, imgW):\n",
    "        self.imgH = imgH\n",
    "        self.imgW = imgW\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((imgH, imgW)),  # 기본 이미지 리사이즈\n",
    "            transforms.RandomApply([self.add_noise()], p=0.3),  # 50% 확률로 노이즈 추가\n",
    "            transforms.RandomApply([self.reduce_resolution()], p=0.3),  # 50% 확률로 해상도 저하\n",
    "            transforms.RandomApply([transforms.RandomRotation(degrees=(-15, 15))], p=0.3),  # 50% 확률로 각도 조정\n",
    "            transforms.RandomApply([self.occlude_image()], p=0.3),  # 50% 확률로 이미지 일부 가리기\n",
    "            transforms.ToTensor()  # 텐서로 변환\n",
    "        ])\n",
    "\n",
    "    def add_noise(self):\n",
    "        \"\"\"이미지에 랜덤 노이즈 추가\"\"\"\n",
    "        def noise(img):\n",
    "            np_img = np.array(img)\n",
    "            row, col, ch = np_img.shape\n",
    "            mean = 0\n",
    "            sigma = 10  # 노이즈 강도\n",
    "            gauss = np.random.normal(mean, sigma, (row, col, ch))\n",
    "            gauss = gauss.reshape(row, col, ch)\n",
    "            noisy = np_img + gauss\n",
    "            noisy = np.clip(noisy, 0, 255).astype(np.uint8)\n",
    "            return Image.fromarray(noisy)\n",
    "        return transforms.Lambda(noise)\n",
    "\n",
    "    def reduce_resolution(self):\n",
    "        \"\"\"이미지의 해상도를 낮춤\"\"\"\n",
    "        def low_res(img):\n",
    "            # 현재 이미지 크기에서 다운샘플링 후 다시 업샘플링\n",
    "            small_img = img.resize((self.imgW // 4, self.imgH // 4), Image.BILINEAR)\n",
    "            return small_img.resize((self.imgW, self.imgH), Image.BILINEAR)\n",
    "        return transforms.Lambda(low_res)\n",
    "\n",
    "    def occlude_image(self):\n",
    "        \"\"\"이미지의 일부를 가림\"\"\"\n",
    "        def occlude(img):\n",
    "            draw = ImageDraw.Draw(img)\n",
    "            # 이미지의 일부를 임의의 사각형으로 가림\n",
    "            w, h = img.size\n",
    "            x1, y1 = random.randint(0, w // 2), random.randint(0, h // 2)\n",
    "            x2, y2 = random.randint(x1 + w // 4, w), random.randint(y1 + h // 4, h)\n",
    "            draw.rectangle([x1, y1, x2, y2], fill=(0, 0, 0))  # 검정색으로 가림\n",
    "            return img\n",
    "        return transforms.Lambda(occlude)\n",
    "\n",
    "    def __call__(self, img):\n",
    "        \"\"\"이미지에 변환 적용\"\"\"\n",
    "        return self.transform(img)\n",
    "\n",
    "\n",
    "def detect_text_craft(image, craft_net):\n",
    "    \"\"\"CRAFT로 텍스트 영역 탐지\"\"\"\n",
    "    img_resized, target_ratio, _ = imgproc.resize_aspect_ratio(image, 1280, interpolation=cv2.INTER_LINEAR, mag_ratio=1.5)\n",
    "    x = imgproc.normalizeMeanVariance(img_resized)\n",
    "    x = torch.from_numpy(x).permute(2, 0, 1).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        y, _ = craft_net(x)\n",
    "\n",
    "    score_text = y[0, :, :, 0].cpu().data.numpy()\n",
    "    score_link = y[0, :, :, 1].cpu().data.numpy()\n",
    "\n",
    "    boxes, polys = craft_utils.getDetBoxes(score_text, score_link, text_threshold=0.7, link_threshold=0.4, low_text=0.4, poly=False)\n",
    "    return boxes\n",
    "\n",
    "\n",
    "def crop_text_regions(image, boxes):\n",
    "    \"\"\"탐지된 텍스트 영역을 자르기\"\"\"\n",
    "    cropped_images = []\n",
    "    for box in boxes:\n",
    "        poly = np.array(box).astype(np.int32).reshape((-1, 2))\n",
    "        x_min = np.min(poly[:, 0])\n",
    "        y_min = np.min(poly[:, 1])\n",
    "        x_max = np.max(poly[:, 0])\n",
    "        y_max = np.max(poly[:, 1])\n",
    "\n",
    "        cropped_img = image[y_min:y_max, x_min:x_max]\n",
    "        cropped_images.append(cropped_img)\n",
    "\n",
    "    return cropped_images\n",
    "\n",
    "\n",
    "def load_label_json(label_path):\n",
    "    \"\"\"라벨 JSON 파일을 로드\"\"\"\n",
    "    with open(label_path, 'r', encoding='utf-8') as f:\n",
    "        label_data = json.load(f)\n",
    "    return label_data['value']  # 이미지의 실제 라벨\n",
    "\n",
    "\n",
    "def train(opt):\n",
    "    \"\"\"STR 모델 학습 루프\"\"\"\n",
    "    data_augmentation = DataAugmentation(opt.imgH, opt.imgW)  # 데이터 증강\n",
    "\n",
    "    for iteration in range(opt.num_iter):\n",
    "        total_loss = 0\n",
    "        # 학습용 데이터 폴더에서 파일 로드\n",
    "        for img_file in os.listdir(opt.train_data):\n",
    "            if img_file.endswith('.jpg'):  # 이미지 파일만 처리\n",
    "                image_path = os.path.join(opt.train_data, img_file)\n",
    "                label_path = os.path.splitext(image_path)[0] + \".json\"\n",
    "\n",
    "                # 이미지 및 라벨 로드\n",
    "                image = imgproc.loadImage(image_path)\n",
    "                label = load_label_json(label_path)\n",
    "\n",
    "                # CRAFT로 텍스트 영역 탐지\n",
    "                boxes = detect_text_craft(image, craft_net)\n",
    "                cropped_images = crop_text_regions(image, boxes)\n",
    "\n",
    "                # 각 자른 이미지 영역을 STR로 학습\n",
    "                for cropped_image in cropped_images:\n",
    "                    # 데이터 증강 적용\n",
    "                    cropped_image_augmented = data_augmentation(cropped_image)\n",
    "\n",
    "                    # 라벨 인코딩\n",
    "                    text, length = converter.encode([label], batch_max_length=opt.batch_max_length)\n",
    "\n",
    "                    # 모델 예측\n",
    "                    preds = str_model(cropped_image_augmented.unsqueeze(0).to(device))\n",
    "                    cost = criterion(preds, text)\n",
    "\n",
    "                    # 손실 역전파\n",
    "                    optimizer.zero_grad()\n",
    "                    cost.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                    total_loss += cost.item()\n",
    "\n",
    "        if iteration % opt.valInterval == 0:\n",
    "            print(f\"Iteration {iteration}, Loss: {total_loss:.4f}\")\n",
    "            validate(opt)\n",
    "\n",
    "\n",
    "def validate(opt):\n",
    "    \"\"\"검증 루틴\"\"\"\n",
    "    AlignCollate_valid = AlignCollate(imgH=opt.imgH, imgW=opt.imgW, keep_ratio_with_pad=True)\n",
    "    valid_dataset = TextRecognitionDataset(root=opt.valid_data, opt=opt)\n",
    "    valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=opt.batch_size, shuffle=True, num_workers=opt.workers, collate_fn=AlignCollate_valid)\n",
    "\n",
    "    str_model.eval()\n",
    "    with torch.no_grad():\n",
    "        valid_loss, valid_accuracy = validation(str_model, criterion, valid_loader, converter, opt)\n",
    "        print(f\"Validation Loss: {valid_loss:.4f}, Validation Accuracy: {valid_accuracy:.4f}\")\n",
    "    str_model.train()\n",
    "\n",
    "\n",
    "# 트레이닝 실행\n",
    "train(opt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bee4481-9cd2-4f5d-a86d-a0461f0f819e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
