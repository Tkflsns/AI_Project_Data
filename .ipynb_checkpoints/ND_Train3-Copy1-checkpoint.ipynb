{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67310744-01b2-4c36-95a6-d8f546ceb813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading images...\n",
      "Filtering the images containing characters which are not in opt.character\n",
      "Filtering the images whose label is longer than opt.batch_max_length\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "num total samples of /: 79840 x 1.0 (total_data_usage_ratio) = 79840\n",
      "num samples of / per batch: 1400 x 1.0 (batch_ratio) = 1400\n",
      "--------------------------------------------------------------------------------\n",
      "Total_batch_size: 1400 = 1400\n",
      "--------------------------------------------------------------------------------\n",
      "Initializing TPS Transformation\n",
      "TPS 초기화: F=20, I_size=(32, 100), I_r_size=(32, 100), I_channel_num=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\KD7-3\\lib\\site-packages\\torch\\functional.py:513: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\TensorShape.cpp:3610.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "D:\\KD7-3\\DataProject\\lincenseplateocr\\modules\\transformation.py:107: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.register_buffer(\"inv_delta_C\", torch.tensor(self._build_inv_delta_C(self.F, self.C)).float())  # F+3 x F+3\n",
      "D:\\KD7-3\\DataProject\\lincenseplateocr\\modules\\transformation.py:108: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.register_buffer(\"P_hat\", torch.tensor(self._build_P_hat(self.F, self.C, self.P)).float())  # n x F+3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TPS Transformation initialized\n",
      "Initializing Feature Extraction: ResNet\n",
      "Feature Extraction initialized with output size: 512\n",
      "Initializing Sequence Modeling with BiLSTM\n",
      "Sequence Modeling initialized\n",
      "Initializing Prediction: Attn\n",
      "Prediction initialized\n",
      "Model: Model(\n",
      "  (Transformation): TPS_SpatialTransformerNetwork(\n",
      "    (LocalizationNetwork): LocalizationNetwork(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (6): ReLU(inplace=True)\n",
      "        (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (10): ReLU(inplace=True)\n",
      "        (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        (12): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (13): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (14): ReLU(inplace=True)\n",
      "        (15): AdaptiveAvgPool2d(output_size=1)\n",
      "      )\n",
      "      (localization_fc1): Sequential(\n",
      "        (0): Linear(in_features=512, out_features=256, bias=True)\n",
      "        (1): ReLU(inplace=True)\n",
      "      )\n",
      "      (localization_fc2): Linear(in_features=256, out_features=40, bias=True)\n",
      "    )\n",
      "    (GridGenerator): GridGenerator()\n",
      "  )\n",
      "  (FeatureExtraction): ResNet_FeatureExtractor(\n",
      "    (ConvNet): ResNet(\n",
      "      (conv0_1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn0_1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv0_2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn0_2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (layer1): Sequential(\n",
      "        (0): BasicBlock(\n",
      "          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (layer2): Sequential(\n",
      "        (0): BasicBlock(\n",
      "          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): BasicBlock(\n",
      "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (maxpool3): MaxPool2d(kernel_size=2, stride=(2, 1), padding=(0, 1), dilation=1, ceil_mode=False)\n",
      "      (layer3): Sequential(\n",
      "        (0): BasicBlock(\n",
      "          (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): BasicBlock(\n",
      "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): BasicBlock(\n",
      "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (3): BasicBlock(\n",
      "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (4): BasicBlock(\n",
      "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (conv3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (layer4): Sequential(\n",
      "        (0): BasicBlock(\n",
      "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): BasicBlock(\n",
      "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): BasicBlock(\n",
      "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (conv4_1): Conv2d(512, 512, kernel_size=(2, 2), stride=(2, 1), padding=(0, 1), bias=False)\n",
      "      (bn4_1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4_2): Conv2d(512, 512, kernel_size=(2, 2), stride=(1, 1), bias=False)\n",
      "      (bn4_2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (AdaptiveAvgPool): AdaptiveAvgPool2d(output_size=(None, 1))\n",
      "  (SequenceModeling): Sequential(\n",
      "    (0): BidirectionalLSTM(\n",
      "      (rnn): LSTM(512, 256, batch_first=True, bidirectional=True)\n",
      "      (linear): Linear(in_features=512, out_features=256, bias=True)\n",
      "    )\n",
      "    (1): BidirectionalLSTM(\n",
      "      (rnn): LSTM(256, 256, batch_first=True, bidirectional=True)\n",
      "      (linear): Linear(in_features=512, out_features=256, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (Prediction): Attention(\n",
      "    (attention_cell): AttentionCell(\n",
      "      (i2h): Linear(in_features=256, out_features=256, bias=False)\n",
      "      (h2h): Linear(in_features=256, out_features=256, bias=True)\n",
      "      (score): Linear(in_features=256, out_features=1, bias=False)\n",
      "      (rnn): LSTMCell(404, 256)\n",
      "    )\n",
      "    (generator): Linear(in_features=256, out_features=148, bias=True)\n",
      "  )\n",
      ")\n",
      "Loading pretrained model from ./lincenseplateocr/pretrained/Fine-Tuned.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_26296\\240480216.py:99: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(opt.saved_model))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 58. 배치를 건너뜁니다.\n",
      "검증 루프 시작 at iteration 100\n",
      "검증 결과 - Loss: 0.1062, Accuracy: 84.35%\n",
      "[100/100000] Train Loss: 0.0685, Valid Loss: 0.1062, Valid Accuracy: 84.3468\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 117. 배치를 건너뜁니다.\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 176. 배치를 건너뜁니다.\n",
      "검증 루프 시작 at iteration 200\n",
      "검증 결과 - Loss: 0.0744, Accuracy: 88.38%\n",
      "[200/100000] Train Loss: 0.0477, Valid Loss: 0.0744, Valid Accuracy: 88.3805\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 235. 배치를 건너뜁니다.\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 294. 배치를 건너뜁니다.\n",
      "검증 루프 시작 at iteration 300\n",
      "검증 결과 - Loss: 0.0782, Accuracy: 88.10%\n",
      "[300/100000] Train Loss: 0.0585, Valid Loss: 0.0782, Valid Accuracy: 88.0995\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 353. 배치를 건너뜁니다.\n",
      "검증 루프 시작 at iteration 400\n",
      "검증 결과 - Loss: 0.0643, Accuracy: 90.61%\n",
      "[400/100000] Train Loss: 0.0455, Valid Loss: 0.0643, Valid Accuracy: 90.6081\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 412. 배치를 건너뜁니다.\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 471. 배치를 건너뜁니다.\n",
      "검증 루프 시작 at iteration 500\n",
      "검증 결과 - Loss: 0.0489, Accuracy: 92.98%\n",
      "[500/100000] Train Loss: 0.0265, Valid Loss: 0.0489, Valid Accuracy: 92.9761\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 530. 배치를 건너뜁니다.\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 589. 배치를 건너뜁니다.\n",
      "검증 루프 시작 at iteration 600\n",
      "검증 결과 - Loss: 0.0525, Accuracy: 92.28%\n",
      "[600/100000] Train Loss: 0.0219, Valid Loss: 0.0525, Valid Accuracy: 92.2838\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 648. 배치를 건너뜁니다.\n",
      "검증 루프 시작 at iteration 700\n",
      "검증 결과 - Loss: 0.0486, Accuracy: 93.01%\n",
      "[700/100000] Train Loss: 0.0267, Valid Loss: 0.0486, Valid Accuracy: 93.0062\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 707. 배치를 건너뜁니다.\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 766. 배치를 건너뜁니다.\n",
      "검증 루프 시작 at iteration 800\n",
      "검증 결과 - Loss: 0.0474, Accuracy: 93.50%\n",
      "[800/100000] Train Loss: 0.0265, Valid Loss: 0.0474, Valid Accuracy: 93.4979\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 825. 배치를 건너뜁니다.\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 884. 배치를 건너뜁니다.\n",
      "검증 루프 시작 at iteration 900\n",
      "검증 결과 - Loss: 0.0469, Accuracy: 93.60%\n",
      "[900/100000] Train Loss: 0.0151, Valid Loss: 0.0469, Valid Accuracy: 93.5982\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 943. 배치를 건너뜁니다.\n",
      "검증 루프 시작 at iteration 1000\n",
      "검증 결과 - Loss: 0.0419, Accuracy: 94.30%\n",
      "[1000/100000] Train Loss: 0.0187, Valid Loss: 0.0419, Valid Accuracy: 94.3006\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 1002. 배치를 건너뜁니다.\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 1061. 배치를 건너뜁니다.\n",
      "검증 루프 시작 at iteration 1100\n",
      "검증 결과 - Loss: 0.0403, Accuracy: 94.23%\n",
      "[1100/100000] Train Loss: 0.0121, Valid Loss: 0.0403, Valid Accuracy: 94.2304\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 1120. 배치를 건너뜁니다.\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 1179. 배치를 건너뜁니다.\n",
      "검증 루프 시작 at iteration 1200\n",
      "검증 결과 - Loss: 0.0417, Accuracy: 94.52%\n",
      "[1200/100000] Train Loss: 0.0134, Valid Loss: 0.0417, Valid Accuracy: 94.5214\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 1238. 배치를 건너뜁니다.\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 1297. 배치를 건너뜁니다.\n",
      "검증 루프 시작 at iteration 1300\n",
      "검증 결과 - Loss: 0.0560, Accuracy: 91.42%\n",
      "[1300/100000] Train Loss: 0.0390, Valid Loss: 0.0560, Valid Accuracy: 91.4208\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 1356. 배치를 건너뜁니다.\n",
      "검증 루프 시작 at iteration 1400\n",
      "검증 결과 - Loss: 0.0424, Accuracy: 94.72%\n",
      "[1400/100000] Train Loss: 0.0122, Valid Loss: 0.0424, Valid Accuracy: 94.7221\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 1415. 배치를 건너뜁니다.\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 1474. 배치를 건너뜁니다.\n",
      "검증 루프 시작 at iteration 1500\n",
      "검증 결과 - Loss: 0.0372, Accuracy: 95.23%\n",
      "[1500/100000] Train Loss: 0.0083, Valid Loss: 0.0372, Valid Accuracy: 95.2338\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 1533. 배치를 건너뜁니다.\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 1592. 배치를 건너뜁니다.\n",
      "검증 루프 시작 at iteration 1600\n",
      "검증 결과 - Loss: 0.0412, Accuracy: 94.56%\n",
      "[1600/100000] Train Loss: 0.0191, Valid Loss: 0.0412, Valid Accuracy: 94.5615\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 1651. 배치를 건너뜁니다.\n",
      "검증 루프 시작 at iteration 1700\n",
      "검증 결과 - Loss: 0.0355, Accuracy: 95.37%\n",
      "[1700/100000] Train Loss: 0.0113, Valid Loss: 0.0355, Valid Accuracy: 95.3743\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 1710. 배치를 건너뜁니다.\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 1769. 배치를 건너뜁니다.\n",
      "검증 루프 시작 at iteration 1800\n",
      "검증 결과 - Loss: 0.0367, Accuracy: 95.49%\n",
      "[1800/100000] Train Loss: 0.0077, Valid Loss: 0.0367, Valid Accuracy: 95.4947\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 1828. 배치를 건너뜁니다.\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 1887. 배치를 건너뜁니다.\n",
      "검증 루프 시작 at iteration 1900\n",
      "검증 결과 - Loss: 0.0380, Accuracy: 95.14%\n",
      "[1900/100000] Train Loss: 0.0067, Valid Loss: 0.0380, Valid Accuracy: 95.1435\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 1946. 배치를 건너뜁니다.\n",
      "검증 루프 시작 at iteration 2000\n",
      "검증 결과 - Loss: 0.0439, Accuracy: 95.08%\n",
      "[2000/100000] Train Loss: 0.0101, Valid Loss: 0.0439, Valid Accuracy: 95.0833\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 2005. 배치를 건너뜁니다.\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 2064. 배치를 건너뜁니다.\n",
      "검증 루프 시작 at iteration 2100\n",
      "검증 결과 - Loss: 0.0362, Accuracy: 95.78%\n",
      "[2100/100000] Train Loss: 0.0046, Valid Loss: 0.0362, Valid Accuracy: 95.7756\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 2123. 배치를 건너뜁니다.\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 2182. 배치를 건너뜁니다.\n",
      "검증 루프 시작 at iteration 2200\n",
      "검증 결과 - Loss: 0.0359, Accuracy: 95.78%\n",
      "[2200/100000] Train Loss: 0.0030, Valid Loss: 0.0359, Valid Accuracy: 95.7756\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 2241. 배치를 건너뜁니다.\n",
      "검증 루프 시작 at iteration 2300\n",
      "검증 결과 - Loss: 0.3542, Accuracy: 66.32%\n",
      "[2300/100000] Train Loss: 0.0352, Valid Loss: 0.3542, Valid Accuracy: 66.3155\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 2300. 배치를 건너뜁니다.\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 2359. 배치를 건너뜁니다.\n",
      "검증 루프 시작 at iteration 2400\n",
      "검증 결과 - Loss: 0.0361, Accuracy: 95.65%\n",
      "[2400/100000] Train Loss: 0.0064, Valid Loss: 0.0361, Valid Accuracy: 95.6452\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 2418. 배치를 건너뜁니다.\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 2477. 배치를 건너뜁니다.\n",
      "검증 루프 시작 at iteration 2500\n",
      "검증 결과 - Loss: 0.0394, Accuracy: 95.65%\n",
      "[2500/100000] Train Loss: 0.0028, Valid Loss: 0.0394, Valid Accuracy: 95.6452\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 2536. 배치를 건너뜁니다.\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 2595. 배치를 건너뜁니다.\n",
      "검증 루프 시작 at iteration 2600\n",
      "검증 결과 - Loss: 0.0428, Accuracy: 95.25%\n",
      "[2600/100000] Train Loss: 0.0067, Valid Loss: 0.0428, Valid Accuracy: 95.2539\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 2654. 배치를 건너뜁니다.\n",
      "검증 루프 시작 at iteration 2700\n",
      "검증 결과 - Loss: 0.0386, Accuracy: 95.58%\n",
      "[2700/100000] Train Loss: 0.0047, Valid Loss: 0.0386, Valid Accuracy: 95.5850\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 2713. 배치를 건너뜁니다.\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 2772. 배치를 건너뜁니다.\n",
      "검증 루프 시작 at iteration 2800\n",
      "검증 결과 - Loss: 0.0367, Accuracy: 95.76%\n",
      "[2800/100000] Train Loss: 0.0027, Valid Loss: 0.0367, Valid Accuracy: 95.7556\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 2831. 배치를 건너뜁니다.\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 2890. 배치를 건너뜁니다.\n",
      "검증 루프 시작 at iteration 2900\n",
      "검증 결과 - Loss: 0.0375, Accuracy: 95.79%\n",
      "[2900/100000] Train Loss: 0.0020, Valid Loss: 0.0375, Valid Accuracy: 95.7857\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 2949. 배치를 건너뜁니다.\n",
      "검증 루프 시작 at iteration 3000\n",
      "검증 결과 - Loss: 0.0362, Accuracy: 95.78%\n",
      "[3000/100000] Train Loss: 0.0014, Valid Loss: 0.0362, Valid Accuracy: 95.7756\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 3008. 배치를 건너뜁니다.\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 3067. 배치를 건너뜁니다.\n",
      "검증 루프 시작 at iteration 3100\n",
      "검증 결과 - Loss: 0.0355, Accuracy: 95.84%\n",
      "[3100/100000] Train Loss: 0.0013, Valid Loss: 0.0355, Valid Accuracy: 95.8358\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 3126. 배치를 건너뜁니다.\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 3185. 배치를 건너뜁니다.\n",
      "검증 루프 시작 at iteration 3200\n",
      "검증 결과 - Loss: 0.0427, Accuracy: 95.06%\n",
      "[3200/100000] Train Loss: 0.0051, Valid Loss: 0.0427, Valid Accuracy: 95.0632\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 3244. 배치를 건너뜁니다.\n",
      "검증 루프 시작 at iteration 3300\n",
      "검증 결과 - Loss: 0.0369, Accuracy: 95.54%\n",
      "[3300/100000] Train Loss: 0.0053, Valid Loss: 0.0369, Valid Accuracy: 95.5449\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 3303. 배치를 건너뜁니다.\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 3362. 배치를 건너뜁니다.\n",
      "검증 루프 시작 at iteration 3400\n",
      "검증 결과 - Loss: 0.0370, Accuracy: 95.74%\n",
      "[3400/100000] Train Loss: 0.0025, Valid Loss: 0.0370, Valid Accuracy: 95.7355\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 3421. 배치를 건너뜁니다.\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 3480. 배치를 건너뜁니다.\n",
      "검증 루프 시작 at iteration 3500\n",
      "검증 결과 - Loss: 0.0358, Accuracy: 96.02%\n",
      "[3500/100000] Train Loss: 0.0017, Valid Loss: 0.0358, Valid Accuracy: 96.0165\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 3539. 배치를 건너뜁니다.\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 3598. 배치를 건너뜁니다.\n",
      "검증 루프 시작 at iteration 3600\n",
      "검증 결과 - Loss: 1.0273, Accuracy: 31.36%\n",
      "[3600/100000] Train Loss: 0.3590, Valid Loss: 1.0273, Valid Accuracy: 31.3566\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 3657. 배치를 건너뜁니다.\n",
      "검증 루프 시작 at iteration 3700\n",
      "검증 결과 - Loss: 0.0366, Accuracy: 95.38%\n",
      "[3700/100000] Train Loss: 0.0054, Valid Loss: 0.0366, Valid Accuracy: 95.3843\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 3716. 배치를 건너뜁니다.\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 3775. 배치를 건너뜁니다.\n",
      "검증 루프 시작 at iteration 3800\n",
      "검증 결과 - Loss: 0.0391, Accuracy: 95.44%\n",
      "[3800/100000] Train Loss: 0.0061, Valid Loss: 0.0391, Valid Accuracy: 95.4445\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 3834. 배치를 건너뜁니다.\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 3893. 배치를 건너뜁니다.\n",
      "검증 루프 시작 at iteration 3900\n",
      "검증 결과 - Loss: 0.0467, Accuracy: 94.56%\n",
      "[3900/100000] Train Loss: 0.0076, Valid Loss: 0.0467, Valid Accuracy: 94.5615\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 3952. 배치를 건너뜁니다.\n",
      "검증 루프 시작 at iteration 4000\n",
      "검증 결과 - Loss: 0.0353, Accuracy: 95.71%\n",
      "[4000/100000] Train Loss: 0.0011, Valid Loss: 0.0353, Valid Accuracy: 95.7054\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 4011. 배치를 건너뜁니다.\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 4070. 배치를 건너뜁니다.\n",
      "검증 루프 시작 at iteration 4100\n",
      "검증 결과 - Loss: 0.0348, Accuracy: 95.96%\n",
      "[4100/100000] Train Loss: 0.0016, Valid Loss: 0.0348, Valid Accuracy: 95.9563\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 4129. 배치를 건너뜁니다.\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 4188. 배치를 건너뜁니다.\n",
      "검증 루프 시작 at iteration 4200\n",
      "검증 결과 - Loss: 0.0367, Accuracy: 95.92%\n",
      "[4200/100000] Train Loss: 0.0035, Valid Loss: 0.0367, Valid Accuracy: 95.9161\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 4247. 배치를 건너뜁니다.\n",
      "검증 루프 시작 at iteration 4300\n",
      "검증 결과 - Loss: 0.0360, Accuracy: 95.93%\n",
      "[4300/100000] Train Loss: 0.0006, Valid Loss: 0.0360, Valid Accuracy: 95.9261\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 4306. 배치를 건너뜁니다.\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 4365. 배치를 건너뜁니다.\n",
      "검증 루프 시작 at iteration 4400\n",
      "검증 결과 - Loss: 0.0373, Accuracy: 95.84%\n",
      "[4400/100000] Train Loss: 0.0008, Valid Loss: 0.0373, Valid Accuracy: 95.8358\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 4424. 배치를 건너뜁니다.\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 4483. 배치를 건너뜁니다.\n",
      "검증 루프 시작 at iteration 4500\n",
      "검증 결과 - Loss: 0.0362, Accuracy: 96.03%\n",
      "[4500/100000] Train Loss: 0.0006, Valid Loss: 0.0362, Valid Accuracy: 96.0265\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 4542. 배치를 건너뜁니다.\n",
      "검증 루프 시작 at iteration 4600\n",
      "검증 결과 - Loss: 0.0361, Accuracy: 96.10%\n",
      "[4600/100000] Train Loss: 0.0015, Valid Loss: 0.0361, Valid Accuracy: 96.0967\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 4601. 배치를 건너뜁니다.\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 4660. 배치를 건너뜁니다.\n",
      "검증 루프 시작 at iteration 4700\n",
      "검증 결과 - Loss: 0.0350, Accuracy: 96.13%\n",
      "[4700/100000] Train Loss: 0.0135, Valid Loss: 0.0350, Valid Accuracy: 96.1268\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 4719. 배치를 건너뜁니다.\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 4778. 배치를 건너뜁니다.\n",
      "검증 루프 시작 at iteration 4800\n",
      "검증 결과 - Loss: 0.0359, Accuracy: 96.06%\n",
      "[4800/100000] Train Loss: 0.0011, Valid Loss: 0.0359, Valid Accuracy: 96.0566\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 4837. 배치를 건너뜁니다.\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 4896. 배치를 건너뜁니다.\n",
      "검증 루프 시작 at iteration 4900\n",
      "검증 결과 - Loss: 0.0344, Accuracy: 96.25%\n",
      "[4900/100000] Train Loss: 0.0008, Valid Loss: 0.0344, Valid Accuracy: 96.2472\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 4955. 배치를 건너뜁니다.\n",
      "검증 루프 시작 at iteration 5000\n",
      "검증 결과 - Loss: 0.0345, Accuracy: 96.08%\n",
      "[5000/100000] Train Loss: 0.0005, Valid Loss: 0.0345, Valid Accuracy: 96.0767\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 5014. 배치를 건너뜁니다.\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 5073. 배치를 건너뜁니다.\n",
      "검증 루프 시작 at iteration 5100\n",
      "검증 결과 - Loss: 0.0346, Accuracy: 96.20%\n",
      "[5100/100000] Train Loss: 0.0003, Valid Loss: 0.0346, Valid Accuracy: 96.1971\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 5132. 배치를 건너뜁니다.\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 5191. 배치를 건너뜁니다.\n",
      "검증 루프 시작 at iteration 5200\n",
      "검증 결과 - Loss: 0.0357, Accuracy: 96.20%\n",
      "[5200/100000] Train Loss: 0.0003, Valid Loss: 0.0357, Valid Accuracy: 96.1971\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 5250. 배치를 건너뜁니다.\n",
      "검증 루프 시작 at iteration 5300\n",
      "검증 결과 - Loss: 0.0370, Accuracy: 95.58%\n",
      "[5300/100000] Train Loss: 0.0088, Valid Loss: 0.0370, Valid Accuracy: 95.5850\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 5309. 배치를 건너뜁니다.\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 5368. 배치를 건너뜁니다.\n",
      "검증 루프 시작 at iteration 5400\n",
      "검증 결과 - Loss: 0.0339, Accuracy: 96.00%\n",
      "[5400/100000] Train Loss: 0.0015, Valid Loss: 0.0339, Valid Accuracy: 95.9964\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 5427. 배치를 건너뜁니다.\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 5486. 배치를 건너뜁니다.\n",
      "검증 루프 시작 at iteration 5500\n",
      "검증 결과 - Loss: 0.0335, Accuracy: 96.20%\n",
      "[5500/100000] Train Loss: 0.0010, Valid Loss: 0.0335, Valid Accuracy: 96.1971\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 5545. 배치를 건너뜁니다.\n",
      "검증 루프 시작 at iteration 5600\n",
      "검증 결과 - Loss: 0.0433, Accuracy: 95.42%\n",
      "[5600/100000] Train Loss: 0.0042, Valid Loss: 0.0433, Valid Accuracy: 95.4244\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 5604. 배치를 건너뜁니다.\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 5663. 배치를 건너뜁니다.\n",
      "검증 루프 시작 at iteration 5700\n",
      "검증 결과 - Loss: 0.0334, Accuracy: 96.16%\n",
      "[5700/100000] Train Loss: 0.0005, Valid Loss: 0.0334, Valid Accuracy: 96.1569\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 5722. 배치를 건너뜁니다.\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 5781. 배치를 건너뜁니다.\n",
      "검증 루프 시작 at iteration 5800\n",
      "검증 결과 - Loss: 0.0355, Accuracy: 96.07%\n",
      "[5800/100000] Train Loss: 0.0023, Valid Loss: 0.0355, Valid Accuracy: 96.0666\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 5840. 배치를 건너뜁니다.\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 5899. 배치를 건너뜁니다.\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 5958. 배치를 건너뜁니다.\n",
      "검증 루프 시작 at iteration 6000\n",
      "검증 결과 - Loss: 0.0329, Accuracy: 96.31%\n",
      "[6000/100000] Train Loss: 0.0009, Valid Loss: 0.0329, Valid Accuracy: 96.3074\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 6017. 배치를 건너뜁니다.\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 6076. 배치를 건너뜁니다.\n",
      "검증 루프 시작 at iteration 6100\n",
      "검증 결과 - Loss: 0.0338, Accuracy: 96.29%\n",
      "[6100/100000] Train Loss: 0.0004, Valid Loss: 0.0338, Valid Accuracy: 96.2874\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 6135. 배치를 건너뜁니다.\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 6194. 배치를 건너뜁니다.\n",
      "검증 루프 시작 at iteration 6200\n",
      "검증 결과 - Loss: 0.0347, Accuracy: 96.14%\n",
      "[6200/100000] Train Loss: 0.0010, Valid Loss: 0.0347, Valid Accuracy: 96.1369\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 6253. 배치를 건너뜁니다.\n",
      "검증 루프 시작 at iteration 6300\n",
      "검증 결과 - Loss: 0.0336, Accuracy: 96.45%\n",
      "[6300/100000] Train Loss: 0.0004, Valid Loss: 0.0336, Valid Accuracy: 96.4479\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 6312. 배치를 건너뜁니다.\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 6371. 배치를 건너뜁니다.\n",
      "검증 루프 시작 at iteration 6400\n",
      "검증 결과 - Loss: 0.0405, Accuracy: 95.48%\n",
      "[6400/100000] Train Loss: 0.0032, Valid Loss: 0.0405, Valid Accuracy: 95.4846\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 6430. 배치를 건너뜁니다.\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 6489. 배치를 건너뜁니다.\n",
      "검증 루프 시작 at iteration 6500\n",
      "검증 결과 - Loss: 0.0354, Accuracy: 96.03%\n",
      "[6500/100000] Train Loss: 0.0005, Valid Loss: 0.0354, Valid Accuracy: 96.0265\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 6548. 배치를 건너뜁니다.\n",
      "검증 루프 시작 at iteration 6600\n",
      "검증 결과 - Loss: 0.0363, Accuracy: 96.12%\n",
      "[6600/100000] Train Loss: 0.0014, Valid Loss: 0.0363, Valid Accuracy: 96.1168\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 6607. 배치를 건너뜁니다.\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 6666. 배치를 건너뜁니다.\n",
      "검증 루프 시작 at iteration 6700\n",
      "검증 결과 - Loss: 0.0352, Accuracy: 96.27%\n",
      "[6700/100000] Train Loss: 0.0005, Valid Loss: 0.0352, Valid Accuracy: 96.2673\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 6725. 배치를 건너뜁니다.\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 6784. 배치를 건너뜁니다.\n",
      "검증 루프 시작 at iteration 6800\n",
      "검증 결과 - Loss: 0.0394, Accuracy: 95.65%\n",
      "[6800/100000] Train Loss: 0.0016, Valid Loss: 0.0394, Valid Accuracy: 95.6452\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 6843. 배치를 건너뜁니다.\n",
      "검증 루프 시작 at iteration 6900\n",
      "검증 결과 - Loss: 0.0350, Accuracy: 96.33%\n",
      "[6900/100000] Train Loss: 0.0020, Valid Loss: 0.0350, Valid Accuracy: 96.3275\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 6902. 배치를 건너뜁니다.\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 6961. 배치를 건너뜁니다.\n",
      "검증 루프 시작 at iteration 7000\n",
      "검증 결과 - Loss: 0.0356, Accuracy: 96.37%\n",
      "[7000/100000] Train Loss: 0.0010, Valid Loss: 0.0356, Valid Accuracy: 96.3677\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 7020. 배치를 건너뜁니다.\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 7079. 배치를 건너뜁니다.\n",
      "검증 루프 시작 at iteration 7100\n",
      "검증 결과 - Loss: 0.0364, Accuracy: 96.38%\n",
      "[7100/100000] Train Loss: 0.0012, Valid Loss: 0.0364, Valid Accuracy: 96.3777\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 7138. 배치를 건너뜁니다.\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 7197. 배치를 건너뜁니다.\n",
      "검증 루프 시작 at iteration 7200\n",
      "검증 결과 - Loss: 0.0356, Accuracy: 96.20%\n",
      "[7200/100000] Train Loss: 0.0002, Valid Loss: 0.0356, Valid Accuracy: 96.1971\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 7256. 배치를 건너뜁니다.\n",
      "검증 루프 시작 at iteration 7300\n",
      "검증 결과 - Loss: 0.0362, Accuracy: 96.43%\n",
      "[7300/100000] Train Loss: 0.0021, Valid Loss: 0.0362, Valid Accuracy: 96.4279\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 7315. 배치를 건너뜁니다.\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 7374. 배치를 건너뜁니다.\n",
      "검증 루프 시작 at iteration 7400\n",
      "검증 결과 - Loss: 0.0366, Accuracy: 96.38%\n",
      "[7400/100000] Train Loss: 0.0003, Valid Loss: 0.0366, Valid Accuracy: 96.3777\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 7433. 배치를 건너뜁니다.\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 7492. 배치를 건너뜁니다.\n",
      "검증 루프 시작 at iteration 7500\n",
      "검증 결과 - Loss: 0.0360, Accuracy: 96.41%\n",
      "[7500/100000] Train Loss: 0.0005, Valid Loss: 0.0360, Valid Accuracy: 96.4078\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 7551. 배치를 건너뜁니다.\n",
      "검증 루프 시작 at iteration 7600\n",
      "검증 결과 - Loss: 0.0362, Accuracy: 96.33%\n",
      "[7600/100000] Train Loss: 0.0003, Valid Loss: 0.0362, Valid Accuracy: 96.3275\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 7610. 배치를 건너뜁니다.\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 7669. 배치를 건너뜁니다.\n",
      "검증 루프 시작 at iteration 7700\n",
      "검증 결과 - Loss: 0.0369, Accuracy: 96.48%\n",
      "[7700/100000] Train Loss: 0.0018, Valid Loss: 0.0369, Valid Accuracy: 96.4780\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 7728. 배치를 건너뜁니다.\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 7787. 배치를 건너뜁니다.\n",
      "검증 루프 시작 at iteration 7800\n",
      "검증 결과 - Loss: 0.0357, Accuracy: 96.45%\n",
      "[7800/100000] Train Loss: 0.0002, Valid Loss: 0.0357, Valid Accuracy: 96.4479\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 7846. 배치를 건너뜁니다.\n",
      "검증 루프 시작 at iteration 7900\n",
      "검증 결과 - Loss: 0.0364, Accuracy: 96.44%\n",
      "[7900/100000] Train Loss: 0.0006, Valid Loss: 0.0364, Valid Accuracy: 96.4379\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 7905. 배치를 건너뜁니다.\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 7964. 배치를 건너뜁니다.\n",
      "검증 루프 시작 at iteration 8000\n",
      "검증 결과 - Loss: 0.0403, Accuracy: 95.71%\n",
      "[8000/100000] Train Loss: 0.0034, Valid Loss: 0.0403, Valid Accuracy: 95.7054\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 8023. 배치를 건너뜁니다.\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 8082. 배치를 건너뜁니다.\n",
      "검증 루프 시작 at iteration 8100\n",
      "검증 결과 - Loss: 0.0377, Accuracy: 96.01%\n",
      "[8100/100000] Train Loss: 0.0005, Valid Loss: 0.0377, Valid Accuracy: 96.0064\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 8141. 배치를 건너뜁니다.\n",
      "검증 루프 시작 at iteration 8200\n",
      "검증 결과 - Loss: 0.0894, Accuracy: 88.70%\n",
      "[8200/100000] Train Loss: 0.0037, Valid Loss: 0.0894, Valid Accuracy: 88.7016\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 8200. 배치를 건너뜁니다.\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 8259. 배치를 건너뜁니다.\n",
      "검증 루프 시작 at iteration 8300\n",
      "검증 결과 - Loss: 0.0380, Accuracy: 95.95%\n",
      "[8300/100000] Train Loss: 0.0007, Valid Loss: 0.0380, Valid Accuracy: 95.9462\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 8318. 배치를 건너뜁니다.\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 8377. 배치를 건너뜁니다.\n",
      "검증 루프 시작 at iteration 8400\n",
      "검증 결과 - Loss: 0.0405, Accuracy: 95.50%\n",
      "[8400/100000] Train Loss: 0.0036, Valid Loss: 0.0405, Valid Accuracy: 95.5047\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 8436. 배치를 건너뜁니다.\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 8495. 배치를 건너뜁니다.\n",
      "검증 루프 시작 at iteration 8500\n",
      "검증 결과 - Loss: 0.0479, Accuracy: 93.83%\n",
      "[8500/100000] Train Loss: 0.0137, Valid Loss: 0.0479, Valid Accuracy: 93.8290\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 8554. 배치를 건너뜁니다.\n",
      "검증 루프 시작 at iteration 8600\n",
      "검증 결과 - Loss: 0.0360, Accuracy: 95.92%\n",
      "[8600/100000] Train Loss: 0.0029, Valid Loss: 0.0360, Valid Accuracy: 95.9161\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 8613. 배치를 건너뜁니다.\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 8672. 배치를 건너뜁니다.\n",
      "검증 루프 시작 at iteration 8700\n",
      "검증 결과 - Loss: 0.0372, Accuracy: 95.79%\n",
      "[8700/100000] Train Loss: 0.0017, Valid Loss: 0.0372, Valid Accuracy: 95.7857\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 8731. 배치를 건너뜁니다.\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 8790. 배치를 건너뜁니다.\n",
      "검증 루프 시작 at iteration 8800\n",
      "검증 결과 - Loss: 0.0367, Accuracy: 95.94%\n",
      "[8800/100000] Train Loss: 0.0019, Valid Loss: 0.0367, Valid Accuracy: 95.9362\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 8849. 배치를 건너뜁니다.\n",
      "검증 루프 시작 at iteration 8900\n",
      "검증 결과 - Loss: 0.0345, Accuracy: 96.17%\n",
      "[8900/100000] Train Loss: 0.0008, Valid Loss: 0.0345, Valid Accuracy: 96.1670\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 8908. 배치를 건너뜁니다.\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 8967. 배치를 건너뜁니다.\n",
      "검증 루프 시작 at iteration 9000\n",
      "검증 결과 - Loss: 0.0361, Accuracy: 96.04%\n",
      "[9000/100000] Train Loss: 0.0012, Valid Loss: 0.0361, Valid Accuracy: 96.0365\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 9026. 배치를 건너뜁니다.\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 9085. 배치를 건너뜁니다.\n",
      "검증 루프 시작 at iteration 9100\n",
      "검증 결과 - Loss: 0.0357, Accuracy: 96.20%\n",
      "[9100/100000] Train Loss: 0.0005, Valid Loss: 0.0357, Valid Accuracy: 96.1971\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 9144. 배치를 건너뜁니다.\n",
      "검증 루프 시작 at iteration 9200\n",
      "검증 결과 - Loss: 0.6043, Accuracy: 66.05%\n",
      "[9200/100000] Train Loss: 0.2874, Valid Loss: 0.6043, Valid Accuracy: 66.0546\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 9203. 배치를 건너뜁니다.\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 9262. 배치를 건너뜁니다.\n",
      "검증 루프 시작 at iteration 9300\n",
      "검증 결과 - Loss: 0.0388, Accuracy: 95.19%\n",
      "[9300/100000] Train Loss: 0.0034, Valid Loss: 0.0388, Valid Accuracy: 95.1937\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 9321. 배치를 건너뜁니다.\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 9380. 배치를 건너뜁니다.\n",
      "검증 루프 시작 at iteration 9400\n",
      "검증 결과 - Loss: 0.0358, Accuracy: 95.84%\n",
      "[9400/100000] Train Loss: 0.0012, Valid Loss: 0.0358, Valid Accuracy: 95.8358\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 9439. 배치를 건너뜁니다.\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 9498. 배치를 건너뜁니다.\n",
      "검증 루프 시작 at iteration 9500\n",
      "검증 결과 - Loss: 0.0376, Accuracy: 95.74%\n",
      "[9500/100000] Train Loss: 0.0015, Valid Loss: 0.0376, Valid Accuracy: 95.7355\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 9557. 배치를 건너뜁니다.\n",
      "검증 루프 시작 at iteration 9600\n",
      "검증 결과 - Loss: 0.0354, Accuracy: 96.12%\n",
      "[9600/100000] Train Loss: 0.0007, Valid Loss: 0.0354, Valid Accuracy: 96.1168\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 9616. 배치를 건너뜁니다.\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 9675. 배치를 건너뜁니다.\n",
      "검증 루프 시작 at iteration 9700\n",
      "검증 결과 - Loss: 0.0373, Accuracy: 95.87%\n",
      "[9700/100000] Train Loss: 0.0009, Valid Loss: 0.0373, Valid Accuracy: 95.8659\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 9734. 배치를 건너뜁니다.\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 9793. 배치를 건너뜁니다.\n",
      "검증 루프 시작 at iteration 9800\n",
      "검증 결과 - Loss: 0.0363, Accuracy: 96.15%\n",
      "[9800/100000] Train Loss: 0.0011, Valid Loss: 0.0363, Valid Accuracy: 96.1469\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 9852. 배치를 건너뜁니다.\n",
      "검증 루프 시작 at iteration 9900\n",
      "검증 결과 - Loss: 0.0360, Accuracy: 96.30%\n",
      "[9900/100000] Train Loss: 0.0009, Valid Loss: 0.0360, Valid Accuracy: 96.2974\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 9911. 배치를 건너뜁니다.\n",
      "StopIteration 발생 at loader 0\n",
      "빈 배치가 감지되었습니다. 빈 배치를 건너뜁니다.\n",
      "빈 배치 발생 at iteration 9970. 배치를 건너뜁니다.\n",
      "검증 루프 시작 at iteration 10000\n",
      "검증 결과 - Loss: 0.0358, Accuracy: 96.16%\n",
      "[10000/100000] Train Loss: 0.0004, Valid Loss: 0.0358, Valid Accuracy: 96.1569\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 169\u001b[0m\n\u001b[0;32m    166\u001b[0m opt\u001b[38;5;241m.\u001b[39mvalInterval \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m  \u001b[38;5;66;03m# 검증 주기 설정\u001b[39;00m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;66;03m# 학습 실행\u001b[39;00m\n\u001b[1;32m--> 169\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 116\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(opt)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m iteration \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(opt\u001b[38;5;241m.\u001b[39mnum_iter):\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 116\u001b[0m         image_tensors, labels \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    117\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m image_tensors \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    118\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m빈 배치 발생 at iteration \u001b[39m\u001b[38;5;132;01m{\u001b[39;00miteration\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. 배치를 건너뜁니다.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mD:\\KD7-3\\DataProject\\lincenseplateocr\\dataset.py:191\u001b[0m, in \u001b[0;36mBatch_Balanced_Dataset.get_batch\u001b[1;34m(self, drop_rate)\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, data_loader_iter \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataloader_iter_list):\n\u001b[0;32m    190\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 191\u001b[0m         image, text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata_loader_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    192\u001b[0m         \u001b[38;5;66;03m# image = augmentor(image)  # 데이터 증강 적용\u001b[39;00m\n\u001b[0;32m    193\u001b[0m         balanced_batch_images\u001b[38;5;241m.\u001b[39mappend(image)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\KD7-3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\KD7-3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:673\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    672\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 673\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    675\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\KD7-3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:50\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__:\n\u001b[1;32m---> 50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\KD7-3\\lib\\site-packages\\torch\\utils\\data\\dataset.py:420\u001b[0m, in \u001b[0;36mSubset.__getitems__\u001b[1;34m(self, indices)\u001b[0m\n\u001b[0;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m    419\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 420\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx]] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\KD7-3\\lib\\site-packages\\torch\\utils\\data\\dataset.py:420\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m    419\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 420\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\KD7-3\\lib\\site-packages\\torch\\utils\\data\\dataset.py:350\u001b[0m, in \u001b[0;36mConcatDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    349\u001b[0m     sample_idx \u001b[38;5;241m=\u001b[39m idx \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcumulative_sizes[dataset_idx \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m--> 350\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatasets\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdataset_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43msample_idx\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32mD:\\KD7-3\\DataProject\\lincenseplateocr\\dataset.py:316\u001b[0m, in \u001b[0;36mLmdbDataset.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    313\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m index \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex range error\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    314\u001b[0m index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfiltered_index_list[index]\n\u001b[1;32m--> 316\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwrite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m txn:\n\u001b[0;32m    317\u001b[0m     label_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel-\u001b[39m\u001b[38;5;132;01m%09d\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mencode() \u001b[38;5;241m%\u001b[39m index\n\u001b[0;32m    318\u001b[0m     label \u001b[38;5;241m=\u001b[39m txn\u001b[38;5;241m.\u001b[39mget(label_key)\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import string\n",
    "\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.init as init\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import numpy as np\n",
    "\n",
    "from lincenseplateocr.utils import CTCLabelConverter, CTCLabelConverterForBaiduWarpctc, AttnLabelConverter, Averager\n",
    "from lincenseplateocr.dataset import hierarchical_dataset, AlignCollate, Batch_Balanced_Dataset\n",
    "from lincenseplateocr.model import Model\n",
    "from lincenseplateocr.test import validation\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "writer = SummaryWriter()\n",
    "\n",
    "# 옵션 부분을 여기서 설정할 수 있게 변경\n",
    "class Options:\n",
    "    def __init__(self):\n",
    "        self.exp_name = 'experiment'\n",
    "        self.train_data = './input/lmdb'\n",
    "        self.valid_data = './modules/Dataset/Valid'\n",
    "        self.manualSeed = 1111\n",
    "        self.workers = 0\n",
    "        self.batch_size = 1400\n",
    "        self.num_iter = 3000\n",
    "        self.valInterval = 20\n",
    "        self.saved_model = './lincenseplateocr/pretrained/Fine-Tuned.pth'\n",
    "        self.FT = True\n",
    "        self.adam = False\n",
    "        self.lr = 1.0\n",
    "        self.beta1 = 0.9\n",
    "        self.rho = 0.95\n",
    "        self.eps = 1e-8\n",
    "        self.grad_clip = 5\n",
    "        self.baiduCTC = False\n",
    "        self.select_data = '/'\n",
    "        self.batch_ratio = '1'\n",
    "        self.total_data_usage_ratio = '1.0'\n",
    "        self.batch_max_length = 25\n",
    "        self.imgH = 32\n",
    "        self.imgW = 100\n",
    "        self.rgb = False\n",
    "        self.character = '0123456789().JNRW_abcdef가강개걍거겅겨견결경계고과관광굥구금기김깅나남너노논누니다대댜더뎡도동두등디라러로루룰리마머명모무문므미바배뱌버베보부북비사산서성세셔소송수시아악안양어여연영오올용우울원육으을이익인자작저전제조종주중지차처천초추출충층카콜타파평포하허호홀후히ㅣ'\n",
    "        self.sensitive = False\n",
    "        self.PAD = False\n",
    "        self.Transformation = 'TPS'\n",
    "        self.FeatureExtraction = 'ResNet'\n",
    "        self.SequenceModeling = 'BiLSTM'\n",
    "        self.Prediction = 'Attn'\n",
    "        self.num_fiducial = 20\n",
    "        self.input_channel = 1\n",
    "        self.output_channel = 512\n",
    "        self.hidden_size = 256\n",
    "        self.num_gpu = torch.cuda.device_count()\n",
    "        self.data_filtering_off = False \n",
    "\n",
    "opt = Options()\n",
    "\n",
    "# 모델을 학습하는 함수\n",
    "def train(opt):\n",
    "    if not opt.data_filtering_off:\n",
    "        print('Filtering the images containing characters which are not in opt.character')\n",
    "        print('Filtering the images whose label is longer than opt.batch_max_length')\n",
    "\n",
    "    train_dataset = Batch_Balanced_Dataset(opt)\n",
    "    AlignCollate_valid = AlignCollate(imgH=opt.imgH, imgW=opt.imgW, keep_ratio_with_pad=opt.PAD)\n",
    "    valid_dataset, valid_dataset_log = hierarchical_dataset(root=opt.valid_data, opt=opt)\n",
    "    valid_loader = torch.utils.data.DataLoader(\n",
    "        valid_dataset, batch_size=opt.batch_size, shuffle=True,\n",
    "        num_workers=int(opt.workers), collate_fn=AlignCollate_valid, pin_memory=True)\n",
    "    \n",
    "    # 모델 설정\n",
    "    if 'CTC' in opt.Prediction:\n",
    "        if opt.baiduCTC:\n",
    "            converter = CTCLabelConverterForBaiduWarpctc(opt.character)\n",
    "        else:\n",
    "            converter = CTCLabelConverter(opt.character)\n",
    "    else:\n",
    "        converter = AttnLabelConverter(opt.character)\n",
    "    opt.num_class = len(converter.character)\n",
    "\n",
    "    if opt.rgb:\n",
    "        opt.input_channel = 3\n",
    "    model = Model(opt)\n",
    "    \n",
    "    print('Model:', model)\n",
    "    model = torch.nn.DataParallel(model).to(device)\n",
    "    model.train()\n",
    "\n",
    "    if opt.saved_model != '':\n",
    "        print(f'Loading pretrained model from {opt.saved_model}')\n",
    "        model.load_state_dict(torch.load(opt.saved_model))\n",
    "\n",
    "    # 손실 함수 및 옵티마이저 설정\n",
    "    if 'CTC' in opt.Prediction:\n",
    "        criterion = torch.nn.CTCLoss(zero_infinity=True).to(device)\n",
    "    else:\n",
    "        criterion = torch.nn.CrossEntropyLoss(ignore_index=0).to(device)\n",
    "\n",
    "    if opt.adam:\n",
    "        optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=opt.lr, betas=(opt.beta1, 0.999))\n",
    "    else:\n",
    "        optimizer = optim.Adadelta(filter(lambda p: p.requires_grad, model.parameters()), lr=opt.lr, rho=opt.rho, eps=opt.eps)\n",
    "\n",
    "    # 학습 루프\n",
    "    start_time = time.time()\n",
    "    for iteration in range(opt.num_iter):\n",
    "        try:\n",
    "            image_tensors, labels = train_dataset.get_batch()\n",
    "            if image_tensors is None or labels is None:\n",
    "                print(f\"빈 배치 발생 at iteration {iteration}. 배치를 건너뜁니다.\")\n",
    "                continue  # 빈 배치를 건너뛰기\n",
    "        except StopIteration:\n",
    "            print(f\"StopIteration 발생 at loader {iteration}\")\n",
    "            continue  # 배치가 끝났을 경우 다음 루프로 넘어감\n",
    "            \n",
    "        image = image_tensors.to(device)\n",
    "        text, length = converter.encode(labels, batch_max_length=opt.batch_max_length)\n",
    "        \n",
    "        if 'CTC' in opt.Prediction:\n",
    "            preds = model(image, text)\n",
    "            preds_size = torch.IntTensor([preds.size(1)] * image.size(0))\n",
    "            preds = preds.log_softmax(2).permute(1, 0, 2)\n",
    "            cost = criterion(preds, text, preds_size, length)\n",
    "        else:\n",
    "            preds = model(image, text[:, :-1])\n",
    "            target = text[:, 1:]\n",
    "            cost = criterion(preds.view(-1, preds.shape[-1]), target.contiguous().view(-1))\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Validation\n",
    "        if (iteration + 1) % opt.valInterval == 0:\n",
    "            print(f\"검증 루프 시작 at iteration {iteration + 1}\")\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                try:\n",
    "                    valid_loss, valid_accuracy, *_ = validation(model, criterion, valid_loader, converter, opt)\n",
    "                    print(f\"검증 결과 - Loss: {valid_loss:.4f}, Accuracy: {valid_accuracy:.2f}%\")\n",
    "                except StopIteration:\n",
    "                    print(f\"StopIteration 발생 at validation {iteration}\")\n",
    "                    continue\n",
    "\n",
    "            model.train()\n",
    "            \n",
    "            print(f\"[{iteration+1}/{opt.num_iter}] Train Loss: {cost.item():.4f}, Valid Loss: {valid_loss:.4f}, Valid Accuracy: {valid_accuracy:.4f}\")\n",
    "            \n",
    "        if (iteration + 1) % 10000 == 0:\n",
    "            torch.save(model.state_dict(), f\"./saved_models/{opt.exp_name}/iter_{iteration+1}.pth\")\n",
    "\n",
    "\n",
    "\n",
    "opt.exp_name = \"Number_Plate_Search\"\n",
    "opt.train_data = \"./lincenseplateocr/input/train/transform\"\n",
    "opt.valid_data = \"./lincenseplateocr/input/Vali/transform\"\n",
    "opt.num_iter = 100000  # 예시로 줄인 값\n",
    "opt.valInterval = 100  # 검증 주기 설정\n",
    "\n",
    "# 학습 실행\n",
    "train(opt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f7a2ce-e0f5-4af3-8c86-a2a4d1dad5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "# GPU 메모리 강제 수집\n",
    "gc.collect()  # Python 객체 수집 (CPU 메모리 해제)\n",
    "torch.cuda.empty_cache()  # GPU 메모리 캐시 해제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b076afa-0f12-4e3e-aee9-99623a6d83f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
